{"metadata":{"continue":"","resourceVersion":"46400834","selfLink":"/apis/compliance.openshift.io/v1alpha1/compliancecheckresults"},"apiVersion":"compliance.openshift.io/v1alpha1","kind":"ComplianceCheckResultList","items":[{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Restrict Automounting of Service Account Tokens\nMounting service account tokens inside pods can provide an avenue\nfor privilege escalation attacks where an attacker is able to\ncompromise a single pod in the cluster.","id":"xccdf_org.ssgproject.content_rule_accounts_restrict_service_account_tokens","instructions":"For each pod in the cluster, review the pod specification and\nensure that pods that do not need to explicitly communicate with\nthe API server have automountServiceAccountToken\nconfigured to false.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"accounts-restrict-service-account-tokens"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-accounts-restrict-service-account-tokens","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692821","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-accounts-restrict-service-account-tokens","uid":"a14ff682-7623-4c4a-8358-be5101dabbd1"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Usage of Unique Service Accounts\nKubernetes provides a default service account which is used by\ncluster workloads where no specific service account is assigned to the pod.\nWhere access to the Kubernetes API from a pod is required, a specific service account\nshould be created for that pod, and rights granted to that service account.\nThis increases auditability of service account rights and access making it\neasier and more accurate to trace potential malicious behaviors to a specific\nservice account and project.","id":"xccdf_org.ssgproject.content_rule_accounts_unique_service_account","instructions":"For each namespace in the cluster, review the rights assigned\nto the default service account. There should be no cluster or local roles\nassigned to the default other than the defaults.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"accounts-unique-service-account"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-accounts-unique-service-account","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692802","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-accounts-unique-service-account","uid":"7265ae86-4468-42d8-a76c-04170074ac08"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Disable the AlwaysAdmit Admission Control Plugin\nallows all\nrequests and does not provide any filtering.","id":"xccdf_org.ssgproject.content_rule_api_server_admission_control_plugin_AlwaysAdmit","instructions":"To verify that the AlwaysAdmit admission control plugin is not set, run the following command:\n$ oc -n openshift-kube-apiserver get configmap config -o json | jq -r '.data.\"config.yaml\"' | jq '.apiServerArguments.\"enable-admission-plugins\"'\nThe output should not contain AlwaysAdmit","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-admission-control-plugin-alwaysadmit"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-api-server-admission-control-plugin-alwaysadmit","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692828","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-admission-control-plugin-alwaysadmit","uid":"bebe93f0-b556-4b11-b84e-8165389bb915"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure that the Admission Control Plugin AlwaysPullImages is not set\n.","id":"xccdf_org.ssgproject.content_rule_api_server_admission_control_plugin_AlwaysPullImages","instructions":"Run the following command:\n$ oc -n openshift-kube-apiserver get configmap config -o json | jq -r '.data.\"config.yaml\"' | jq '.apiServerArguments.\"enable-admission-plugins\"'\nThe output list should not contain \"AlwaysPullImages\".","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-admission-control-plugin-alwayspullimages"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"high","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-api-server-admission-control-plugin-alwayspullimages","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692805","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-admission-control-plugin-alwayspullimages","uid":"50e87d71-3382-472f-8986-469ecdd9d573"},"severity":"high","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Enable the NamespaceLifecycle Admission Control Plugin\nensures that\nobjects cannot be created in non-existent namespaces, and that namespaces\nundergoing termination are not used for creating new objects. This\nis recommended to enforce the integrity of the namespace termination process\nand also for the availability of new objects.","id":"xccdf_org.ssgproject.content_rule_api_server_admission_control_plugin_NamespaceLifecycle","instructions":"To verify that the NamespaceLifecycle plugin is enabled in\nthe apiserver configuration, run:\n$ oc -n openshift-kube-apiserver get configmap config -o json | jq -r '.data.\"config.yaml\"' | jq '.apiServerArguments.\"enable-admission-plugins\"'","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-admission-control-plugin-namespacelifecycle"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-api-server-admission-control-plugin-namespacelifecycle","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692780","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-admission-control-plugin-namespacelifecycle","uid":"bb92e162-119c-4118-acbf-4825ee132792"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Enable the NodeRestriction Admission Control Plugin\nAPI objects\nthat are bound to their node.","id":"xccdf_org.ssgproject.content_rule_api_server_admission_control_plugin_NodeRestriction","instructions":"Ensure that the NodeRestriction plugin is enabled in the list of enabled plugins in\nthe apiserver configuration by running the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | grep 'NodeRestriction'","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-admission-control-plugin-noderestriction"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-api-server-admission-control-plugin-noderestriction","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692688","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-admission-control-plugin-noderestriction","uid":"2cedbe26-7deb-4f41-bb19-708461a1cbe3"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Enable the SecurityContextConstraint Admission Control Plugin\nobjects define a set of conditions that a pod\nmust run with in order to be accepted into the system. Security Context Constraints\nare comprised of settings and strategies that control the security features\na pod has access to and hence this must be used to control pod access\npermissions.","id":"xccdf_org.ssgproject.content_rule_api_server_admission_control_plugin_Scc","instructions":"The SecurityContextConstraint plugin should be enabled in the list of enabled plugins in\nthe apiserver configuration:\n$ oc -n openshift-kube-apiserver get configmap config -o json | jq -r '.data.\"config.yaml\"' | jq '.apiServerArguments.\"enable-admission-plugins\"'","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-admission-control-plugin-scc"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-api-server-admission-control-plugin-scc","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692754","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-admission-control-plugin-scc","uid":"0d690235-a60c-4af2-8f14-d115f00e8e07"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure that the admission control plugin SecurityContextDeny is set if PodSecurityPolicy is not used\nwill deter you from enforcing granular permissions on your pods.","id":"xccdf_org.ssgproject.content_rule_api_server_admission_control_plugin_SecurityContextDeny","instructions":"The SecurityContextDeny plugin should not be enabled in the list of enabled plugins in the apiserver configuration:\n$ oc -n openshift-kube-apiserver get configmap config -o json | jq -r '.data.\"config.yaml\"' | jq '.apiServerArguments.\"enable-admission-plugins\"'","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-admission-control-plugin-securitycontextdeny"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-api-server-admission-control-plugin-securitycontextdeny","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692756","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-admission-control-plugin-securitycontextdeny","uid":"1348190b-4f2e-4e2f-a63d-78bb60feaf39"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Enable the ServiceAccount Admission Control Plugin\nservice account in the same\nnamespace. OpenShift operators should create unique service accounts\nand let the API Server manage its security tokens.","id":"xccdf_org.ssgproject.content_rule_api_server_admission_control_plugin_ServiceAccount","instructions":"The ServiceAccount plugin should be enabled in the list of enabled plugins in\nthe apiserver configuration:\n$ oc -n openshift-kube-apiserver get configmap config -o json | jq -r '.data.\"config.yaml\"' | jq '.apiServerArguments.\"enable-admission-plugins\"'","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-admission-control-plugin-serviceaccount"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-api-server-admission-control-plugin-serviceaccount","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692772","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-admission-control-plugin-serviceaccount","uid":"7d9babbc-d83d-408c-8091-e3b825cb8ff5"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure that anonymous requests to the API Server are authorized\nWhen enabled, requests that are not rejected by other configured\nauthentication methods are treated as anonymous requests. These requests\nare then served by the API server. If you are using RBAC authorization,\nit is generally considered reasonable to allow anonymous access to the\nAPI Server for health checks and discovery purposes, and hence this\nrecommendation is not scored. However, you should consider whether\nanonymous discovery is an acceptable risk for your purposes.","id":"xccdf_org.ssgproject.content_rule_api_server_anonymous_auth","instructions":"Run the following command to view the authorization rules for anonymous requests:\n$ oc describe clusterrolebindings\nMake sure that there exists at least one clusterrolebinding that binds\neither the system:unauthenticated group or the system:anonymous\nuser.\nTo test that an anonymous request is authorized to access the readyz\nendpoint, run:\n$ oc get --as=\"system:anonymous\" --raw='/readyz?verbose'\nIn contrast, a request to list all projects should not be authorized:\n$ oc get --as=\"system:anonymous\" projects","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-anonymous-auth"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-api-server-anonymous-auth","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692711","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-anonymous-auth","uid":"a1302d09-ef0c-40db-acdd-92d7867a0ac9"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure catch-all FlowSchema object for API Priority and Fairness Exists\nAPI objects enforce a limit on the\nnumber of events that the API Server will accept in a given time slice\nIn a large multi-tenant cluster, there might be a small percentage of\nmisbehaving tenants which could have a significant impact on the\nperformance of the cluster overall. It is recommended to limit the rate\nof events that the API Server will accept.","id":"xccdf_org.ssgproject.content_rule_api_server_api_priority_flowschema_catch_all","instructions":"Run the following commands:\noc get flowschema\nand inspect the FlowSchema objects. Make sure that at least the catch-all\nobject exists by calling:\noc describe flowschema catch-all","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-api-priority-flowschema-catch-all"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-api-server-api-priority-flowschema-catch-all","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692815","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-api-priority-flowschema-catch-all","uid":"5bc7a6aa-3921-4fed-beef-d9e0d3bcdc70"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["Note that this is only applicable in OpenShift Container Platform version 4.8\nand higher"]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Enable the APIPriorityAndFairness feature gate\nAPI objects which enforce a limit on the number of\nevents that the API Server will accept in a given time slice In a large\nmulti-tenant cluster, there might be a small percentage of misbehaving\ntenants which could have a significant impact on the performance of\nthe cluster overall. It is recommended to limit the rate of events\nthat the API Server will accept.","id":"xccdf_org.ssgproject.content_rule_api_server_api_priority_gate_enabled","instructions":"To verify that APIPriorityAndFairness is enabled, run the following command:\noc get kubeapiservers.operator.openshift.io cluster -o json | jq '.spec.observedConfig.apiServerArguments[\"feature-gates\"]'\nThe output should contain \"APIPriorityAndFairness=true\"","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-api-priority-gate-enabled"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-api-server-api-priority-gate-enabled","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692774","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-api-priority-gate-enabled","uid":"4d207c84-26e3-4493-88b9-0a63b3c862b5"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure catch-all FlowSchema object for API Priority and Fairness Exists (v1alpha1)\nAPI objects enforce a limit on the\nnumber of events that the API Server will accept in a given time slice\nIn a large multi-tenant cluster, there might be a small percentage of\nmisbehaving tenants which could have a significant impact on the\nperformance of the cluster overall. It is recommended to limit the rate\nof events that the API Server will accept.","id":"xccdf_org.ssgproject.content_rule_api_server_api_priority_v1alpha1_flowschema_catch_all","instructions":"Run the following commands:\noc get flowschema\nand inspect the FlowSchema objects. Make sure that at least the catch-all\nobject exists by calling:\noc describe flowschema catch-all","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-api-priority-v1alpha1-flowschema-catch-all"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-api-server-api-priority-v1alpha1-flowschema-catch-all","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692622","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-api-priority-v1alpha1-flowschema-catch-all","uid":"52ce304b-1c55-4b83-852e-eb5360100285"},"severity":"medium","status":"PASS","warnings":["Note that this rule is only applicable in OpenShift Container Platform\nversions 4.7 and below."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure the Kubernetes API Server Maximum Retained Audit Logs\nOpenShift automatically rotates the log files. Retaining old log files ensures\nOpenShift Operators will have sufficient log data available for carrying out\nany investigation or correlation. For example, if the audit log size is set to\n100 MB and the number of retained log files is set to 10, OpenShift Operators\nwould have approximately 1 GB of log data to use during analysis.","id":"xccdf_org.ssgproject.content_rule_api_server_audit_log_maxbackup","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq '.apiServerArguments[\"audit-log-maxbackup\"][0]'\nThe output should return a value of 10 or as appropriate.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-audit-log-maxbackup"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"low","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-api-server-audit-log-maxbackup","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692658","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-audit-log-maxbackup","uid":"cdaff5c7-3a01-49c8-b10f-671d2af74b01"},"severity":"low","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure Kubernetes API Server Maximum Audit Log Size\nOpenShift automatically rotates log files. Retaining old log files ensures that\nOpenShift Operators have sufficient log data available for carrying out any\ninvestigation or correlation. If you have set file size of 100 MB and the number of\nold log files to keep as 10, there would be approximately 1 GB of log data\navailable for use in analysis.","id":"xccdf_org.ssgproject.content_rule_api_server_audit_log_maxsize","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq '.apiServerArguments[\"audit-log-maxsize\"]'\nThe output should return a value of [\"100\"] or as appropriate.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-audit-log-maxsize"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/automated-remediation":"","compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/automated-remediation":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-api-server-audit-log-maxsize","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692731","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-audit-log-maxsize","uid":"44fd1ce8-f1b3-415a-bf7e-b4ec5e28e139"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure the Audit Log Path\nAuditing of the Kubernetes API Server is not enabled by default. Auditing the API Server\nprovides a security-relevant chronological set of records documenting the sequence\nof activities that have affected the system by users, administrators, or other\nsystem components.","id":"xccdf_org.ssgproject.content_rule_api_server_audit_log_path","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq '.apiServerArguments[\"audit-log-path\"]'\nThe output should return a valid audit log path.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-audit-log-path"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"high","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-api-server-audit-log-path","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692660","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-audit-log-path","uid":"b99207f0-59ca-4fb1-9c19-0026390c595a"},"severity":"high","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"The authorization-mode cannot be AlwaysAllow\nThe API Server, can be configured to allow all requests. This mode should not be used on any production cluster.","id":"xccdf_org.ssgproject.content_rule_api_server_auth_mode_no_aa","instructions":"To verify that the Node authorization mode is be configured and enabled in\nthe apiserver configuration, run:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | grep '\"authorization-mode\":\\[[^]]*\"AlwaysAllow\"'\nThe output should be empty - the \"authorization-mode\" list does NOT contain the \"AlwaysAllow\" authorizer.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-auth-mode-no-aa"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-api-server-auth-mode-no-aa","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692849","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-auth-mode-no-aa","uid":"6aa2d196-2984-48b7-9a52-5b352ade6f80"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure authorization-mode Node is configured\nThe Node authorization mode only allows kubelets to read Secret,\nConfigMap, PersistentVolume, and PersistentVolumeClaim objects\nassociated with their nodes.","id":"xccdf_org.ssgproject.content_rule_api_server_auth_mode_node","instructions":"To verify that Node authorization mode is enabled, run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | grep '\"authorization-mode\":\\[[^]]*\"Node\"'\nThe output should show that the \"authorization-mode\" list contains the \"Node\" authorizer.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-auth-mode-node"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-api-server-auth-mode-node","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692662","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-auth-mode-node","uid":"cd848032-5345-4c96-a97c-1834e7fab2e2"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure authorization-mode RBAC is configured\nRole Based Access Control (RBAC) allows fine-grained control over the\noperations that different entities can perform on different objects in\nthe cluster. Enabling RBAC is critical in regulating access to an\nOpenShift cluster as the RBAC rules specify, given a user, which operations\ncan be executed over a set of namespaced or cluster-wide resources.","id":"xccdf_org.ssgproject.content_rule_api_server_auth_mode_rbac","instructions":"To verify that RBAC authorization mode is enabled, run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | grep '\"authorization-mode\":\\[[^]]*\"RBAC\"'\nThe output should show that the \"authorization-mode\" list contains the \"RBAC\" authorizer.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-auth-mode-rbac"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-api-server-auth-mode-rbac","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692723","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-auth-mode-rbac","uid":"d8d6685d-ad04-4c2e-bda5-58547fd57257"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Disable basic-auth-file for the API Server\nBasic authentication uses plaintext credentials for authentication.\nCurrently the basic authentication credentials last indefinitely, and\nthe password cannot be changed without restarting the API Server. The\nBasic Authentication is currently supported for convenience and is\nnot intended for production workloads.","id":"xccdf_org.ssgproject.content_rule_api_server_basic_auth","instructions":"To verify that basic-auth-file is configured and enabled for the API server, run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq '.apiServerArguments[\"basic-auth-file\"]'\nThe output should be empty as OpenShift does not support basic authentication at all.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-basic-auth"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-api-server-basic-auth","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692751","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-basic-auth","uid":"b6cab4e1-2dc8-446c-984b-4f6c6c4a438b"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure that the bindAddress is set to a relevant secure port\nby default. In OpenShift, the only\nsupported way to access the API server pod is through the load balancer and then through\nthe internal service.  The value is set by the bindAddress argument under the servingInfo\nparameter.","id":"xccdf_org.ssgproject.content_rule_api_server_bind_address","instructions":"Run the following command:\noc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq -r '.servingInfo[\"bindAddress\"]'\nThe output should return 0.0.0.0:6443.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-bind-address"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"low","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-api-server-bind-address","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692692","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-bind-address","uid":"40550287-aaa5-4d65-87c6-5991677bc21b"},"severity":"low","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure the Client Certificate Authority for the API Server\nof\nthe client certificate.","id":"xccdf_org.ssgproject.content_rule_api_server_client_ca","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq '.apiServerArguments[\"client-ca-file\"]'\nThe output should return a configured TLS CA certificate file.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-client-ca"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-api-server-client-ca","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692809","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-client-ca","uid":"e52cd0bd-6185-40e0-97bd-be028781c9ed"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure the Encryption Provider Cipher\nis currently the strongest encryption provider, it should\nbe preferred over other providers.","id":"xccdf_org.ssgproject.content_rule_api_server_encryption_provider_cipher","instructions":"Run the following command:\n$ oc get apiserver cluster -ojson | jq -r '.spec.encryption.type'\nThe output should return aescdc as the encryption type.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-encryption-provider-cipher"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/automated-remediation":"","compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/automated-remediation":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-api-server-encryption-provider-cipher","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692746","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-encryption-provider-cipher","uid":"706bfd19-ce29-4744-9cbf-c0f910c033f8"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure the Encryption Provider\netcd is a highly available key-value store used by OpenShift deployments\nfor persistent storage of all REST API objects. These objects are\nsensitive in nature and should be encrypted at rest to avoid any\ndisclosures.","id":"xccdf_org.ssgproject.content_rule_api_server_encryption_provider_config","instructions":"Run the following command:\n$ oc get apiserver cluster -ojson | jq -r '.spec.encryption.type'\nThe output should return aescdc as the encryption type.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-encryption-provider-config"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/automated-remediation":"","compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/automated-remediation":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-api-server-encryption-provider-config","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692789","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-encryption-provider-config","uid":"f907c9f4-68bd-4063-84b6-0f88e9819353"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure the etcd Certificate Authority for the API Server\netcd is a highly-available key-value store used by OpenShift deployments\nfor persistent storage of all REST API objects. These objects are\nsensitive in nature and should be protected by client authentication. This\nrequires the API Server to identify itself to the etcd server using\na SSL Certificate Authority file.","id":"xccdf_org.ssgproject.content_rule_api_server_etcd_ca","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq '.apiServerArguments[\"etcd-cafile\"]'\nThe output should return a configured CA certificate for ETCD.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-etcd-ca"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-api-server-etcd-ca","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692681","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-etcd-ca","uid":"8f91a3ba-6b55-4198-aa01-11cefb3fa3e3"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure the etcd Certificate for the API Server\netcd is a highly-available key-value store used by OpenShift deployments\nfor persistent storage of all REST API objects. These objects are sensitive\nin nature and should be protected by client authentication. This requires the\nAPI Server to identify itself to the etcd server using a client certificate\nand key.","id":"xccdf_org.ssgproject.content_rule_api_server_etcd_cert","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq -r '.apiServerArguments.\"etcd-certfile\"'\nThe output should return a configured certificate file.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-etcd-cert"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-api-server-etcd-cert","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692823","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-etcd-cert","uid":"ef01e00c-a582-4186-9b5d-58a9696bdb14"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure the etcd Certificate Key for the API Server\netcd is a highly-available key-value store used by OpenShift deployments\nfor persistent storage of all REST API objects. These objects are sensitive\nin nature and should be protected by client authentication. This requires the\nAPI Server to identify itself to the etcd server using a client certificate\nand key.","id":"xccdf_org.ssgproject.content_rule_api_server_etcd_key","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq -r '.apiServerArguments.\"etcd-keyfile\"'\nThe output should return a configured certificate key file.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-etcd-key"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-api-server-etcd-key","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692627","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-etcd-key","uid":"ed26e6f5-6b71-403f-bc77-0d9d9f2bc097"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure that the --kubelet-https argument is set to true\nConnections from the kube-apiserver to kubelets could potentially carry\nsensitive data such as secrets and keys. It is thus important to use\nin-transit encryption for any communication between the apiserver and\nkubelets.","id":"xccdf_org.ssgproject.content_rule_api_server_https_for_kubelet_conn","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq '.apiServerArguments[\"kubelet-https\"]'\nThe output should return true, or no output at all.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-https-for-kubelet-conn"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-api-server-https-for-kubelet-conn","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692624","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-https-for-kubelet-conn","uid":"ac238f55-7395-413e-be5f-0c4c78893532"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Disable Use of the Insecure Bind Address\nIf the API Server is bound to an insecure address the installation would\nbe susceptible to unauthented and unencrypted access to the master node(s).\nThe API Server does not perform authentication checking for insecure\nbinds and the traffic is generally not encrypted.","id":"xccdf_org.ssgproject.content_rule_api_server_insecure_bind_address","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq '.apiServerArguments[\"insecure-bind-address\"]'\nThe output should be empty.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-insecure-bind-address"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-api-server-insecure-bind-address","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692623","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-insecure-bind-address","uid":"992a9dc0-ed1b-47ef-b6b5-d756a971bcc7"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Prevent Insecure Port Access\nConfiguring the API Server on an insecure port would allow unauthenticated\nand unencrypted access to your master node(s). It is assumed firewall rules\nwill be configured to ensure this port is not reachable from outside\nthe cluster, however as a defense in depth measure, OpenShift should not\nbe configured to use insecure ports.","id":"xccdf_org.ssgproject.content_rule_api_server_insecure_port","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq '.apiServerArguments[\"insecure-port\"]'\nThe output should return 0.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-insecure-port"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-api-server-insecure-port","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692628","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-insecure-port","uid":"04e00a53-d33b-40b8-9278-615a4769ab9d"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure the kubelet Certificate Authority for the API Server\nConnections from the API Server to the kubelet are used for fetching logs\nfor pods, attaching (through kubectl) to running pods, and using the kubelet\nport-forwarding functionality. These connections terminate at the kubelet\nHTTPS endpoint. By default, the API Server does not verify the kubelet serving\ncertificate, which makes the connection subject to man-in-the-middle attacks,\nand unsafe to run over untrusted and/or public networks.","id":"xccdf_org.ssgproject.content_rule_api_server_kubelet_certificate_authority","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq -r '.apiServerArguments.\"kubelet-certificate-authority\"'\nThe output should return a configured certificate.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-kubelet-certificate-authority"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"high","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-api-server-kubelet-certificate-authority","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692758","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-kubelet-certificate-authority","uid":"8192a02d-46b9-44b6-ac68-48a0487e438b"},"severity":"high","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure the kubelet Certificate File for the API Server\nBy default the API Server does not authenticate itself to the kublet's\nHTTPS endpoints. Requests from the API Server are treated anonymously.\nConfiguring certificate-based kubelet authentication ensures that the\nAPI Server authenticates itself to kubelets when submitting requests.","id":"xccdf_org.ssgproject.content_rule_api_server_kubelet_client_cert","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq '.apiServerArguments[\"kubelet-client-certificate\"]'\nThe output should return /etc/kubernetes/static-pod-resources/secrets/kubelet-client/tls.crt","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-kubelet-client-cert"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"high","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-api-server-kubelet-client-cert","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692813","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-kubelet-client-cert","uid":"1476a06b-b52e-4ec5-827b-71c92a871db5"},"severity":"high","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure the kubelet Certificate Key for the API Server\nBy default the API Server does not authenticate itself to the kubelet's\nHTTPS endpoints. Requests from the API Server are treated anonymously.\nConfiguring certificate-based kubelet authentication ensures that the\nAPI Server authenticates itself to kubelets when submitting requests.","id":"xccdf_org.ssgproject.content_rule_api_server_kubelet_client_key","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq '.apiServerArguments[\"kubelet-client-key\"]'\nThe output should return /etc/kubernetes/static-pod-resources/secrets/kubelet-client/tls.key","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-kubelet-client-key"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"high","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-api-server-kubelet-client-key","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692656","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-kubelet-client-key","uid":"afba0ac2-8880-40cc-9d85-8ca1186d841e"},"severity":"high","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure all admission control plugins are enabled\nSeveral hardening controls depend on certain API server admission plugins\nbeing enabled. Checking that no admission control plugins are disabled\nhelps assert that all the critical admission control plugins are indeed\nenabled and providing the security benefits required.","id":"xccdf_org.ssgproject.content_rule_api_server_no_adm_ctrl_plugins_disabled","instructions":"To verify that the list of disabled admission plugins is empty, run the following command:\n$ oc -n openshift-kube-apiserver get configmap config -o json | jq -r '.data.\"config.yaml\"' | jq '.apiServerArguments.\"disable-admission-plugins\"'\nThere should be no output.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-no-adm-ctrl-plugins-disabled"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-api-server-no-adm-ctrl-plugins-disabled","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692733","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-no-adm-ctrl-plugins-disabled","uid":"39e6ca9f-1342-4018-adf0-1fadebca3932"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure the openshift-oauth-apiserver service uses TLS\nConnections between the kube-apiserver and the extension\nopenshift-oauth-apiserver could potentially carry sensitive data such\nas secrets and keys. It is important to use in-transit encryption\nfor any communication between the kube-apiserver and the extension\nopenshift-apiserver.","id":"xccdf_org.ssgproject.content_rule_api_server_oauth_https_serving_cert","instructions":"Run the following command:\n$ oc -n openshift-oauth-apiserver describe secret serving-cert\nVerify that the serving-cert for the openshift-apiserver is type\nkubernetes.io/tls and that returned Data includes tls.crt\nand tls.key.\n      Is it the case that The openshift-apiserver serving-cert is not set to type\n<tt>kubernetes.io/tls</tt> and that returned Data does not include <tt>tls.crt</tt>","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-oauth-https-serving-cert"},"creationTimestamp":"2021-06-03T17:09:24Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:24Z"}],"name":"ocp4-cis-api-server-oauth-https-serving-cert","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692871","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-oauth-https-serving-cert","uid":"b9318ea2-353b-4270-a02e-1cac5b6bc96a"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure the openshift-oauth-apiserver service uses TLS\nConnections between the kube-apiserver and the extension\nopenshift-apiserver could potentially carry sensitive data such\nas secrets and keys. It is important to use in-transit encryption\nfor any communication between the kube-apiserver and the extension\nopenshift-apiserver.","id":"xccdf_org.ssgproject.content_rule_api_server_openshift_https_serving_cert","instructions":"Run the following command:\n$ oc -n openshift-apiserver describe secret serving-cert\nVerify that the serving-cert for the openshift-apiserver is type\nkubernetes.io/tls and that returned Data includes tls.crt\nand tls.key.\n      Is it the case that The openshift-apiserver serving-cert is not set to type\n<tt>kubernetes.io/tls</tt> and that returned Data does not include <tt>tls.crt</tt>","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-openshift-https-serving-cert"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-api-server-openshift-https-serving-cert","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692618","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-openshift-https-serving-cert","uid":"e1acc9a6-da4f-4b36-b09d-b0aba3053a9e"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Profiling is protected by RBAC\nProfiling allows for the identification of specific performance bottlenecks.\nIt generates a significant amount of program data that could potentially be\nexploited to uncover system and program details. \nTo ensure the collected data is not exploited, profiling endpoints are secured\nvia RBAC (see cluster-debugger role). By default, the profiling endpoints are\naccessible only by users bound to cluster-admin or cluster-debugger role.\nProfiling can not be disabled.","id":"xccdf_org.ssgproject.content_rule_api_server_profiling_protected_by_rbac","instructions":"To verify that the cluster-debugger role is configured correctly,\nrun the following command:\n$ oc get clusterroles cluster-debugger -o jsonpath='{.rules[0].nonResourceURLs}'\nand verify that the /metrics path is included there.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-profiling-protected-by-rbac"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-api-server-profiling-protected-by-rbac","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692684","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-profiling-protected-by-rbac","uid":"01d335da-b04e-4936-bbcd-4e7809a74952"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure the API Server Minimum Request Timeout\nSetting global request timout allows extending the API Server request\ntimeout limit to a duration appropriate to the user's connection speed.  By\ndefault, it is set to 1800 seconds which might not be suitable for some\nenvironments. Setting the limit too low may result in excessive timeouts,\nand a limit that is too large may exhaust the API Server resources making\nit prone to Denial-of-Service attack. It is recommended to set this limit\nas appropriate and change the default limit of 1800 seconds only if needed.","id":"xccdf_org.ssgproject.content_rule_api_server_request_timeout","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq '.apiServerArguments[\"min-request-timeout\"]'\nThe output should return .","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-request-timeout"},"creationTimestamp":"2021-06-03T17:09:24Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:24Z"}],"name":"ocp4-cis-api-server-request-timeout","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692873","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-request-timeout","uid":"06092143-8a27-44b1-beb4-f86d2ce15917"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure that the service-account-lookup argument is set to true\nis not enabled, the apiserver\nonly verifies that the authentication token is valid, and\ndoes not validate that the service account token mentioned\nin the request is actually present in etcd. This allows\nusing a service account token even after the corresponding\nservice account is deleted. This is an example of time of\ncheck to time of use security issue.","id":"xccdf_org.ssgproject.content_rule_api_server_service_account_lookup","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -o json | \\\n    jq -r '.data[\"config.yaml\"]' | \\\n    jq -r '.apiServerArguments[\"service-account-lookup\"]'\nThe output should return true.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-service-account-lookup"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-api-server-service-account-lookup","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692617","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-service-account-lookup","uid":"b248594f-00eb-4d31-bca4-abdb577dbc1a"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure the Service Account Public Key for the API Server\nis specified\nto the apiserver, it uses the private key from the TLS serving\ncertificate to verify service account tokens. To ensure that the\nkeys for service account tokens are rotated as needed, a\nseparate public/private key pair should be used for signing service\naccount tokens.","id":"xccdf_org.ssgproject.content_rule_api_server_service_account_public_key","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq -r .serviceAccountPublicKeyFiles\nThe output should return configured certificate key file(s).","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-service-account-public-key"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-api-server-service-account-public-key","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692673","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-service-account-public-key","uid":"823e578f-01f2-479b-9f11-ed03031141c1"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure the Certificate for the API Server\nAPI Server communication contains sensitive parameters that should remain\nencrypted in transit. Configure the API Server to serve only HTTPS\ntraffic.","id":"xccdf_org.ssgproject.content_rule_api_server_tls_cert","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq -r '.apiServerArguments.\"tls-cert-file\"'\nThe output should return /etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-tls-cert"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-api-server-tls-cert","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692664","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-tls-cert","uid":"5ce862a5-e1cc-4dcf-ac84-90cdbedd5ffc"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Use Strong Cryptographic Ciphers on the API Server\nTLS ciphers have had a number of known vulnerabilities and weaknesses,\nwhich can reduce the protection provided. By default, OpenShift supports\na number of TLS ciphersuites including some that have security concerns,\nweakening the protection provided.","id":"xccdf_org.ssgproject.content_rule_api_server_tls_cipher_suites","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq '.servingInfo[\"cipherSuites\"]'\nVerify that the set of ciphers contains only the following:\n\n\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\n\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\n\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\n\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\n\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256\",\n\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-tls-cipher-suites"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-api-server-tls-cipher-suites","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692715","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-tls-cipher-suites","uid":"d29b2071-8cde-49b2-b530-c914f6718601"},"severity":"medium","status":"PASS","warnings":["Once configured, API Server clients that cannot support modern\ncryptographic ciphers will not be able to make connections to the API\nserver."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure the Certificate Key for the API Server\nAPI Server communication contains sensitive parameters that should remain\nencrypted in transit. Configure the API Server to serve only HTTPS\ntraffic.","id":"xccdf_org.ssgproject.content_rule_api_server_tls_private_key","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq -r '.apiServerArguments.\"tls-private-key-file\"'\nThe output should return /etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-tls-private-key"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-api-server-tls-private-key","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692782","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-tls-private-key","uid":"6906bd70-83b7-49f7-9476-fc0e22518979"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Disable Token-based Authentication\nThe token-based authentication utilizes static tokens to authenticate\nrequests to the API Server. The tokens are stored in clear-text in a file\non the API Server, and cannot be revoked or rotated without restarting the\nAPI Server.","id":"xccdf_org.ssgproject.content_rule_api_server_token_auth","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq '.apiServerArguments' | grep \"token-auth-file\"\nThe output should be empty as OpenShift does not support token-based authentication at all.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"api-server-token-auth"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"high","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-api-server-token-auth","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692686","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-api-server-token-auth","uid":"b580b59c-7733-4a00-8c97-8b747e1c94e5"},"severity":"high","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure that Audit Log Forwarding Is Enabled\nRetaining logs ensures the ability to go back in time to investigate or correlate any events.\nOffloading audit logs from the cluster ensures that an attacker that has access to the cluster will not be able to\ntamper with the logs because of the logs being stored off-site.","id":"xccdf_org.ssgproject.content_rule_audit_log_forwarding_enabled","instructions":"Run the following command:\noc get clusterlogforwarders instance -n openshift-logging -ojson | jq -r '.spec.pipelines[].inputRefs | contains([\"audit\"])'\nThe output should return true.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"audit-log-forwarding-enabled"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-audit-log-forwarding-enabled","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692713","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-audit-log-forwarding-enabled","uid":"95313e82-ed06-4894-8caf-39765954e429"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure that the cluster's audit profile is properly set\nLogging is an important detective control for all systems, to detect potential\nunauthorised access.","id":"xccdf_org.ssgproject.content_rule_audit_profile_set","instructions":"Run the following command to retrieve the current audit profile:\n$ oc get apiservers cluster -ojsonpath='{.spec.audit.profile}'\nMake sure the profile returned matches the one that should be used.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"audit-profile-set"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-audit-profile-set","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692680","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-audit-profile-set","uid":"9f6a895e-9327-4e68-956f-ad7b25f527ee"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure that the CNI in use supports Network Policies\nKubernetes network policies are enforced by the CNI plugin in use. As such\nit is important to ensure that the CNI plugin supports both Ingress and\nEgress network policies.","id":"xccdf_org.ssgproject.content_rule_configure_network_policies","instructions":"Verify on OpenShift that the NetworkPolicy plugin is being used:\n$ oc explain networkpolicy\nThe resulting output should be an explanation of the NetworkPolicy resource.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"configure-network-policies"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"high","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-configure-network-policies","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692652","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-configure-network-policies","uid":"eadcd6ac-c2d1-42f2-ac48-3165df33392b"},"severity":"high","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure that application Namespaces have Network Policies defined.\nRunning different applications on the same Kubernetes cluster creates a risk of one\ncompromised application attacking a neighboring application. Network segmentation is\nimportant to ensure that containers can communicate only with those they are supposed\nto. When a network policy is introduced to a given namespace, all traffic not allowed\nby the policy is denied. However, if there are no network policies in a namespace all\ntraffic will be allowed into and out of the pods in that namespace.","id":"xccdf_org.ssgproject.content_rule_configure_network_policies_namespaces","instructions":"Verify on OpenShift namespaces that network policies are in use:\n$ oc get networkpolicy --all-namespaces\nEnsure that each namespace defined in the cluster has at least one NetworkPolicy.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"configure-network-policies-namespaces"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"high","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-configure-network-policies-namespaces","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692675","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-configure-network-policies-namespaces","uid":"255d426c-d80c-49ff-93a1-e394b2f80222"},"severity":"high","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Controller insecure port argument is unset\nThe Controller Manager API service is used for health and metrics\ninformation and is available without authentication or encryption. As such, it\nshould only be bound to a localhost interface to minimize the cluster's\nattack surface.","id":"xccdf_org.ssgproject.content_rule_controller_insecure_port_disabled","instructions":"To verify that port is configured correctly,\nrun the following command:\n$ oc get configmaps config -n openshift-kube-controller-manager -ojson |   jq -r '.data[\"config.yaml\"]' | jq '.extendedArguments[\"port\"][]'\nVerify that it's disabled (the value is 0).","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"controller-insecure-port-disabled"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"low","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-controller-insecure-port-disabled","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692629","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-controller-insecure-port-disabled","uid":"d4ec358f-e2ef-4df4-a0a4-f93bd7733d9c"},"severity":"low","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure that the RotateKubeletServerCertificate argument is set\nEnabling kubelet certificate rotation causes the kubelet to both request\na serving certificate after bootstrapping its client credentials and rotate the\ncertificate as its existing credentials expire. This automated periodic rotation\nensures that there are no downtimes due to expired certificates and thus\naddressing the availability in the C/I/A security triad.","id":"xccdf_org.ssgproject.content_rule_controller_rotate_kubelet_server_certs","instructions":"To verify that RotateKubeletServerCertificate is configured correctly,\nrun the following command:\n$ oc get configmaps config -n openshift-kube-controller-manager -ojson | jq -r '.data[\"config.yaml\"]' | jq -r '.extendedArguments[\"feature-gates\"]'\nThe output should return RotateKubeletServerCertificate=true.\n      Is it the case that <tt>RotateKubeletServerCertificate</tt> argument is set to <tt>false</tt> in the","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"controller-rotate-kubelet-server-certs"},"creationTimestamp":"2021-06-03T17:09:24Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:24Z"}],"name":"ocp4-cis-controller-rotate-kubelet-server-certs","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692865","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-controller-rotate-kubelet-server-certs","uid":"b6eec684-be93-4df0-a054-25be7b108797"},"severity":"medium","status":"PASS","warnings":["This recommendation only applies if you let kubelets get their\ncertificates from the API Server. In case your certificates come from an\noutside Certificate Authority/tool (e.g. Vault) then you need to take care\nof rotation yourself"]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Controller secure-port argument is set\nThe Controller Manager API service is used for health and metrics\ninformation and is available without authentication or encryption. As such, it\nshould only be bound to a localhost interface to minimize the cluster's\nattack surface.","id":"xccdf_org.ssgproject.content_rule_controller_secure_port","instructions":"To verify that secure-port is configured correctly,\nrun the following command:\n$ oc get configmaps config -n openshift-kube-controller-manager -ojson |   jq -r '.data[\"config.yaml\"]' | jq '.extendedArguments[\"secure-port\"][]'\nVerify that it's using an appropriate port (the value is not 0).","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"controller-secure-port"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"low","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-controller-secure-port","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692666","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-controller-secure-port","uid":"32f06a7f-c934-413e-80af-98d3e43e6009"},"severity":"low","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure the Service Account Certificate Authority Key for the Controller Manager\nService accounts authenticate to the API using tokens signed by a private RSA\nkey. The authentication layer verifies the signature using a matching public RSA key.\nConfiguring the certificate authority file ensures that the API server's signing\ncertificates are validated.","id":"xccdf_org.ssgproject.content_rule_controller_service_account_ca","instructions":"To verify that root-ca-file is configured correctly,\nrun the following command:\n$ oc get configmaps config -n openshift-kube-controller-manager -ojson | jq -r '.data[\"config.yaml\"]' | jq -r '.extendedArguments[\"root-ca-file\"]'\nThe output should return a configured certificate authority file.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"controller-service-account-ca"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-controller-service-account-ca","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692736","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-controller-service-account-ca","uid":"398f6679-c13e-4a65-8c6a-2342554b1edc"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure the Service Account Private Key for the Controller Manager\nBy default if no private key file is specified to the\nAPI Server, the API Server uses the private key from the TLS serving\ncertificate to verify service account tokens. To ensure that the keys\nfor service account tokens could be rotated as needed, a separate\npublic/private key pair should be used for signing service account\ntokens.","id":"xccdf_org.ssgproject.content_rule_controller_service_account_private_key","instructions":"To verify that service-account-private-key-file is configured correctly,\nrun the following command:\n$ oc get configmaps config -n openshift-kube-controller-manager -ojson | jq -r '.data[\"config.yaml\"]' | jq -r '.extendedArguments[\"service-account-private-key-file\"]'\nThe output should return a configured private key file.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"controller-service-account-private-key"},"creationTimestamp":"2021-06-03T17:09:24Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:24Z"}],"name":"ocp4-cis-controller-service-account-private-key","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692854","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-controller-service-account-private-key","uid":"186fe1bc-21b8-4a5e-98d0-382f18959e5c"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure that use-service-account-credentials is enabled\nruns each\ncontrol loop within the contoller manager using a separate service\naccount credential. When used in combination with RBAC, this ensures\nthat the control loops run with the minimum permissions required to\nperform their intended tasks.","id":"xccdf_org.ssgproject.content_rule_controller_use_service_account","instructions":"To verify that service-account-credentials is configured correctly,\nrun the following command:\n$ oc get configmaps config -n openshift-kube-controller-manager -ojson | jq -r '.data[\"config.yaml\"]' | jq -r '.extendedArguments[\"use-service-account-credentials\"]'\nThe value of use-service-account-credentials should be true.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"controller-use-service-account"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-controller-use-service-account","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692638","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-controller-use-service-account","uid":"d1b3982b-2667-4de2-83db-af5332e5c903"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Disable etcd Self-Signed Certificates\nWithout cryptographic integrity protections, information can be\naltered by unauthorized users without detection. Using self-signed\ncertificates ensures that the certificates are never validated\nagainst a certificate authority and could lead to compromised\nand invalidated data.","id":"xccdf_org.ssgproject.content_rule_etcd_auto_tls","instructions":"Run the following command:\n$ oc get cm/etcd-pod -n openshift-etcd -o yaml\nThe etcd pod configuration contained in the configmap should not\ncontain the --auto-tls=true flag.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"etcd-auto-tls"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-etcd-auto-tls","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692819","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-etcd-auto-tls","uid":"2f271031-5392-4976-afb0-af72d302d5f0"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure That The etcd Client Certificate Is Correctly Set\nWithout cryptographic integrity protections, information can be\naltered by unauthorized users without detection.","id":"xccdf_org.ssgproject.content_rule_etcd_cert_file","instructions":"Run the following command:\noc get -nopenshift-etcd cm etcd-pod -oyaml | grep -E \"\\-\\-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-[a-z]+/etcd-serving-NODE_NAME.crt\"\nVerify that there is a certificate configured.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"etcd-cert-file"},"creationTimestamp":"2021-06-03T17:09:24Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:24Z"}],"name":"ocp4-cis-etcd-cert-file","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692859","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-etcd-cert-file","uid":"834c0721-d089-4b52-b61f-1ce475f0cebd"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Enable The Client Certificate Authentication\nWithout cryptographic integrity protections, information can be\naltered by unauthorized users without detection.","id":"xccdf_org.ssgproject.content_rule_etcd_client_cert_auth","instructions":"Run the following command:\noc get -nopenshift-etcd cm etcd-pod -oyaml | grep \"\\-\\-client-cert-auth=\"\nThe parameter should be set to true.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"etcd-client-cert-auth"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-etcd-client-cert-auth","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692762","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-etcd-client-cert-auth","uid":"e07fe21c-68a7-4255-a0aa-e3440d58f7f1"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure That The etcd Key File Is Correctly Set\nWithout cryptographic integrity protections, information can be\naltered by unauthorized users without detection.","id":"xccdf_org.ssgproject.content_rule_etcd_key_file","instructions":"Run the following command:\noc get -nopenshift-etcd cm etcd-pod -oyaml | grep \"\\-\\-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-[a-z]+/etcd-serving-NODE_NAME.key\"\nVerify that there is a private key configured.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"etcd-key-file"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-etcd-key-file","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692798","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-etcd-key-file","uid":"58afb2d5-b634-4ec7-bdf1-f054a99f03a9"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Disable etcd Peer Self-Signed Certificates\nWithout cryptographic integrity protections, information can be\naltered by unauthorized users without detection. Using self-signed\ncertificates ensures that the certificates are never validated\nagainst a certificate authority and could lead to compromised\nand invalidated data.","id":"xccdf_org.ssgproject.content_rule_etcd_peer_auto_tls","instructions":"Run the following command:\n$ oc get cm/etcd-pod -n openshift-etcd -o yaml\nThe etcd pod configuration contained in the configmap should not\ncontain the --peer-auto-tls=true flag.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"etcd-peer-auto-tls"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-etcd-peer-auto-tls","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692787","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-etcd-peer-auto-tls","uid":"15bc6181-61d7-4c3c-a1aa-ef5ae3f1158d"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure That The etcd Peer Client Certificate Is Correctly Set\nWithout cryptographic integrity protections, information can be\naltered by unauthorized users without detection.","id":"xccdf_org.ssgproject.content_rule_etcd_peer_cert_file","instructions":"Run the following command:\noc get -nopenshift-etcd cm etcd-pod -oyaml | grep \"\\-\\-peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-[a-z]+/etcd-peer-NODE_NAME.crt\"\nVerify that there is a certificate configured.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"etcd-peer-cert-file"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-etcd-peer-cert-file","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692625","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-etcd-peer-cert-file","uid":"869d1caa-188f-476f-8c17-c58178652972"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Enable The Peer Client Certificate Authentication\nWithout cryptographic integrity protections, information can be\naltered by unauthorized users without detection.","id":"xccdf_org.ssgproject.content_rule_etcd_peer_client_cert_auth","instructions":"Run the following command:\noc get -nopenshift-etcd cm etcd-pod -oyaml | grep \"\\-\\-peer-client-cert-auth=\"\nThe parameter should be set to true.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"etcd-peer-client-cert-auth"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-etcd-peer-client-cert-auth","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692626","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-etcd-peer-client-cert-auth","uid":"e60a7d8b-ec64-4424-a515-820e63fc728e"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure That The etcd Peer Key File Is Correctly Set\nWithout cryptographic integrity protections, information can be\naltered by unauthorized users without detection.","id":"xccdf_org.ssgproject.content_rule_etcd_peer_key_file","instructions":"Run the following command:\noc get -nopenshift-etcd cm etcd-pod -oyaml | grep \"\\-\\-peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-[a-z]+/etcd-peer-NODE_NAME.key\"\nVerify that there is a private key configured.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"etcd-peer-key-file"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-etcd-peer-key-file","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692740","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-etcd-peer-key-file","uid":"4f68cfd9-c667-451e-bc81-e7959e8bff98"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Worker Proxy Kubeconfig File\nThe kubeconfig file for kube-proxy provides permissions to the kube-proxy service.\nThe proxy kubeconfig file contains information about the administrative configuration of the\nOpenShift cluster that is configured on the system. Protection of this file is\ncritical for OpenShift security.\n\nThe file is provided via a ConfigMap mount, so the kubelet itself makes sure that the\nfile permissions are appropriate for the container taking it into use.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_proxy_kubeconfig","instructions":"Run the following command:\n\n $ for i in $(oc get pods -n openshift-sdn -l app=sdn -oname)\n   do\n      oc exec -n openshift-sdn $i -- stat -Lc %U:%G /config/kube-proxy-config.yaml\n   done\n\nThe output should be root:root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-proxy-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:24Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:24Z"}],"name":"ocp4-cis-file-groupowner-proxy-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692862","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-file-groupowner-proxy-kubeconfig","uid":"482e02b9-18e0-4b09-a528-89b7ba9f0305"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Worker Proxy Kubeconfig File\nThe kubeconfig file for kube-proxy provides permissions to the kube-proxy service.\nThe proxy kubeconfig file contains information about the administrative configuration of the\nOpenShift cluster that is configured on the system. Protection of this file is\ncritical for OpenShift security.\n\nThe file is provided via a ConfigMap mount, so the kubelet itself makes sure that the\nfile permissions are appropriate for the container taking it into use.","id":"xccdf_org.ssgproject.content_rule_file_owner_proxy_kubeconfig","instructions":"Run the following command:\n\n $ for i in $(oc get pods -n openshift-sdn -l app=sdn -oname)\n   do\n      oc exec -n openshift-sdn $i -- stat -Lc %U:%G /config/kube-proxy-config.yaml\n   done\n\nThe output should be root:root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-proxy-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-file-owner-proxy-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692766","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-file-owner-proxy-kubeconfig","uid":"8a5333e3-2ffe-46ce-ad75-a9a46d8b221d"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Worker Proxy Kubeconfig File\nThe kube-proxy kubeconfig file controls various parameters of the kube-proxy\nservice in the worker node. If used, you should restrict its file permissions\nto maintain the integrity of the file. The file should be writable by only\nthe administrators on the system.\n\nThe kube-proxy runs with the kubeconfig parameters configured as\na Kubernetes ConfigMap instead of a file. In this case, there is no proxy\nkubeconfig file. But appropriate permissions still need to be set in the\nConfigMap mount.","id":"xccdf_org.ssgproject.content_rule_file_permissions_proxy_kubeconfig","instructions":"Run the following command:\n$ oc get -nopenshift-sdn ds sdn -ojson | jq -r '.spec.template.spec.volumes[] | select(.configMap.name == \"sdn-config\") | .configMap.defaultMode'\nThe output should return a value of 420.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-proxy-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-file-permissions-proxy-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692768","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-file-permissions-proxy-kubeconfig","uid":"486fb67c-28c3-471c-bc2e-ee757434bec8"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Apply Security Context to Your Pods and Containers\nA security context defines the operating system security settings (uid, gid,\ncapabilities, SELinux role, etc..) applied to a container. When designing your\ncontainers and pods, make sure that you configure the security context for your\npods, containers, and volumes. A security context is a property defined in the\ndeployment yaml. It controls the security parameters that will be assigned to\nthe pod/container/volume. There are two levels of security context: pod level\nsecurity context, and container level security context.","id":"xccdf_org.ssgproject.content_rule_general_apply_scc","instructions":"Review the pod definitions in your cluster and verify that you have security\ncontexts defined as appropriate.  OpenShift's Security Context Constraint\nfeature is on by default in OpenShift 4 and applied to all pods deployed. SCC\nselection is determined by a combination of the values in the securityContext\nand the rolebindings for the account deploying the pod.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"general-apply-scc"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-general-apply-scc","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692654","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-general-apply-scc","uid":"8c4af809-4051-4f87-9cde-339acb2006f7"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Manage Image Provenance Using ImagePolicyWebhook\nImage Policy ensures that only approved container images are allowed to be ran on the OpenShift platform.","id":"xccdf_org.ssgproject.content_rule_general_configure_imagepolicywebhook","instructions":"To ensure that an image policy is configured, review the output\nreturned from the following command:\n$ oc get image.config.openshift.io/cluster -o yaml","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"general-configure-imagepolicywebhook"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-general-configure-imagepolicywebhook","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692669","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-general-configure-imagepolicywebhook","uid":"f8bf0ed4-a146-4bbb-b9a1-d9014c58fc54"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"The default namespace should not be used\nResources in a Kubernetes cluster should be segregated by namespace, to allow\nfor security controls to be applied at that level and to make it easier to\nmanage resources.","id":"xccdf_org.ssgproject.content_rule_general_default_namespace_use","instructions":"Run the following command to list objects in the default namespace:\n$ oc get all -n default\nThe only entries there should be system-managed resources such as the\nkubernetes and openshift service.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"general-default-namespace-use"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-general-default-namespace-use","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692613","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-general-default-namespace-use","uid":"f8d7dbde-9545-422a-a91a-3c4045d11fb4"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Seccomp Profile Pod Definitions\nSeccomp (secure computing mode) is used to restrict the set of system calls\napplications can make, allowing cluster administrators greater control over\nthe security of workloads running in the cluster. Kubernetes disables\nseccomp profiles by default for historical reasons. You should enable it to\nensure that the workloads have restricted actions available within the\ncontainer.","id":"xccdf_org.ssgproject.content_rule_general_default_seccomp_profile","instructions":"In OpenShift 4, CRI-O is the supported runtime. CRI-O runs unconfined by\ndefault in order to meet CRI conformance criteria.  On RHEL CoreOS, the\ndefault seccomp policy is associated with CRI-O and stored in\n/etc/crio/seccomp.json.  The default profile is applied when the user asks\nfor the runtime/default profile via annotation to the pod and when the\nassociated SCC allows use of the specified seccomp profile.\n\nConfiguration of allowable seccomp profiles is managed through OpenShift\nSecurity Context Constraints.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"general-default-seccomp-profile"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-general-default-seccomp-profile","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692760","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-general-default-seccomp-profile","uid":"ae157c3f-2409-4b86-ac4c-ced680cc27e7"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Create administrative boundaries between resources using namespaces\nLimiting the scope of user permissions can reduce the impact of mistakes or\nmalicious activities. A Kubernetes namespace allows you to partition created\nresources into logically named groups. Resources created in one namespace can\nbe hidden from other namespaces. By default, each resource created by a user\nin Kubernetes cluster runs in a default namespace, called default. You can\ncreate additional namespaces and attach resources and users to them. You can\nuse Kubernetes Authorization plugins to create policies that segregate access\nto namespace resources between different users.","id":"xccdf_org.ssgproject.content_rule_general_namespaces_in_use","instructions":"OpenShift projects wrap Kubernetes namespaces and are used by default in\nOpenShift 4.  Run the following command and review the namespaces created in\nthe cluster.  $ oc get namespaces Ensure that the namespaces are\nthe ones you need and are adequately administered.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"general-namespaces-in-use"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-general-namespaces-in-use","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692650","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-general-namespaces-in-use","uid":"2842a9f4-9e9b-460e-a4fa-ae9a27df1e34"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure An Identity Provider\n","id":"xccdf_org.ssgproject.content_rule_idp_is_configured","instructions":"Run the following command to list the identity providers configured:\n$ oc get oauths cluster -ojsonpath='{.spec.identityProviders}' | jq \nMake sure that there exists at least one item referenced by the above path.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"idp-is-configured"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-idp-is-configured","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692709","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-idp-is-configured","uid":"eb2b13bb-86f8-43bf-8f8a-5920901f736a"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure That The kubelet Client Certificate Is Correctly Set\nWithout cryptographic integrity protections, information can be\naltered by unauthorized users without detection.","id":"xccdf_org.ssgproject.content_rule_kubelet_configure_tls_cert","instructions":"Run the following command on the kubelet node(s):\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq -r '.apiServerArguments[\"kubelet-client-certificate\"]'\nVerify that a client certificate is configured.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-configure-tls-cert"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-kubelet-configure-tls-cert","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692703","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-kubelet-configure-tls-cert","uid":"0ad2d613-40ba-45a3-b57c-5bfc96251bd4"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure That The kubelet Server Key Is Correctly Set\nWithout cryptographic integrity protections, information can be\naltered by unauthorized users without detection.","id":"xccdf_org.ssgproject.content_rule_kubelet_configure_tls_key","instructions":"Run the following command on the kubelet node(s):\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq -r '.apiServerArguments[\"kubelet-client-key\"]'\nVerify that a client certificate is configured.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-configure-tls-key"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-kubelet-configure-tls-key","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692671","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-kubelet-configure-tls-key","uid":"1e065454-0c9c-4504-a09f-d3877b631b00"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"kubelet - Disable the Read-Only Port\n. This ensures only\nauthenticated connections are able to receive information about the OpenShift\nsystem.","id":"xccdf_org.ssgproject.content_rule_kubelet_disable_readonly_port","instructions":"Run the following command:\n$ oc get configmap config -n openshift-kube-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq -r '.apiServerArguments[\"kubelet-read-only-port\"]'\nThe output should be 0.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-disable-readonly-port"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-kubelet-disable-readonly-port","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692800","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-kubelet-disable-readonly-port","uid":"77b9be39-184d-4fba-ac09-160201b4b7b8"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure A Unique CA Certificate for etcd\nThe Kubernetes API server and etcd utilize separate CA certificates in\nOpenShift.  This ensures that the etcd data is still protected in the event\nthat the API server CA is compromised.","id":"xccdf_org.ssgproject.content_rule_etcd_unique_ca","instructions":"Run the following command:\noc debug node/$NODE -- diff /host/etc/kubernetes/static-pod-resources/etcd-certs/configmaps/etcd-serving-ca/ca-bundle.crt /host/etc/kubernetes/static-pod-resources/kube-apiserver-certs/configmaps/client-ca/ca-bundle.crt\nwhere $NODE is a master node. If you don't see diff output\nthe differences, you might have a compromise and should isolate the cluster.\nOpenShift will use separate PKIs by default.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"etcd-unique-ca"},"creationTimestamp":"2021-06-03T17:09:34Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:34Z"}],"name":"ocp4-cis-node-master-etcd-unique-ca","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693043","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-etcd-unique-ca","uid":"46758c5d-60a9-466a-acee-bd7bc3720a93"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The OpenShift Container Network Interface Files\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_cni_conf","instructions":"To check the group ownership of /etc/cni/net.d/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/cni/net.d/*\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-cni-conf"},"creationTimestamp":"2021-06-03T17:09:28Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:28Z"}],"name":"ocp4-cis-node-master-file-groupowner-cni-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692903","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-cni-conf","uid":"ac8e2534-6cf3-42f9-a7ca-718079a246fd"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The OpenShift Controller Manager Kubeconfig File\nThe Controller Manager's kubeconfig contains information about how the\ncomponent will access the API server. You should set its file ownership to\nmaintain the integrity of the file.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_controller_manager_kubeconfig","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/configmaps/controller-manager-kubeconfig/kubeconfig,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/configmaps/controller-manager-kubeconfig/kubeconfig\n  If properly configured, the output should indicate the following group-owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-controller-manager-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:30Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:30Z"}],"name":"ocp4-cis-node-master-file-groupowner-controller-manager-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692970","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-controller-manager-kubeconfig","uid":"e651bb3d-5574-4158-b660-b149fc812824"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Controller\nManager service. The aforementioned service is only running on\nthe nodes labeled \"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Etcd Database Directory\netcd is a highly-available key-value store used by Kubernetes deployments for\npersistent storage of all of its REST API objects. This data directory should\nbe protected from any unauthorized reads or writes.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_etcd_data_dir","instructions":"To check the group ownership of /var/lib/etcd/member/,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/lib/etcd/member/\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-etcd-data-dir"},"creationTimestamp":"2021-06-03T17:09:33Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:33Z"}],"name":"ocp4-cis-node-master-file-groupowner-etcd-data-dir","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693008","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-etcd-data-dir","uid":"19fba490-43f7-448b-8c50-18d759e9116c"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Etcd Write-Ahead-Log Files\netcd is a highly-available key-value store used by Kubernetes deployments for\npersistent storage of all of its REST API objects. This data directory should\nbe protected from any unauthorized reads or writes.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_etcd_data_files","instructions":"To check the group ownership of /var/lib/etcd/member/wal/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/lib/etcd/member/wal/*\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-etcd-data-files"},"creationTimestamp":"2021-06-03T17:09:34Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:34Z"}],"name":"ocp4-cis-node-master-file-groupowner-etcd-data-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693049","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-etcd-data-files","uid":"691cf5d1-9022-4a4d-b4b7-37486ee558d6"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The etcd Member Pod Specification File\nThe etcd pod specification file controls various parameters that\nset the behavior of the etcd service in the master node. etcd is a\nhighly-available key-value store which Kubernetes uses for persistent\nstorage of all of its REST API object. You should restrict its file\npermissions to maintain the integrity of the file. The file should be\nwritable by only the administrators on the system.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_etcd_member","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/etcd-pod-*/etcd-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/static-pod-resources/etcd-pod-*/etcd-pod.yaml\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-etcd-member"},"creationTimestamp":"2021-06-03T17:09:34Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:34Z"}],"name":"ocp4-cis-node-master-file-groupowner-etcd-member","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693073","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-etcd-member","uid":"ce833bc5-6267-4067-8205-a04ebdbf86f4"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Etcd PKI Certificate Files\nOpenShift makes use of a number of certificates as part of its operation.\nYou should verify the ownership of the directory containing the PKI\ninformation and all files in that directory to maintain their integrity.\nThe directory and files should be owned by the system administrator.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_etcd_pki_cert_files","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/*/*/*/*.crt,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/*/*/*/*.crt\n  If properly configured, the output should indicate the following group-owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-etcd-pki-cert-files"},"creationTimestamp":"2021-06-03T17:09:31Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:31Z"}],"name":"ocp4-cis-node-master-file-groupowner-etcd-pki-cert-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692984","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-etcd-pki-cert-files","uid":"1583aaa9-7f82-494d-bba4-8573793ffbce"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The OpenShift SDN Container Network Interface Plugin IP Address Allocations\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_ip_allocations","instructions":"To check the group ownership of /var/lib/cni/networks/openshift-sdn/.*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/lib/cni/networks/openshift-sdn/.*\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-ip-allocations"},"creationTimestamp":"2021-06-03T17:09:28Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:28Z"}],"name":"ocp4-cis-node-master-file-groupowner-ip-allocations","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692918","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-ip-allocations","uid":"d4baa772-5747-441c-afe6-db987c4036eb"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Kubernetes API Server Pod Specification File\nThe Kubernetes specification file contains information about the configuration of the\nKubernetes API Server that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_kube_apiserver","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/kube-apiserver-pod-*/kube-apiserver-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/static-pod-resources/kube-apiserver-pod-*/kube-apiserver-pod.yaml\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-kube-apiserver"},"creationTimestamp":"2021-06-03T17:09:31Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:31Z"}],"name":"ocp4-cis-node-master-file-groupowner-kube-apiserver","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692978","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-kube-apiserver","uid":"949c3beb-cf55-413c-9761-85af555edf98"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes API Server service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Kubernetes Controller Manager Pod Specification File\nThe Kubernetes specification file contains information about the configuration of the\nKubernetes Controller Manager Server that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_kube_controller_manager","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/kube-controller-manager-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/kube-controller-manager-pod.yaml\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-kube-controller-manager"},"creationTimestamp":"2021-06-03T17:09:28Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:28Z"}],"name":"ocp4-cis-node-master-file-groupowner-kube-controller-manager","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692906","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-kube-controller-manager","uid":"79320664-0134-4e57-a6f7-e5e836c4dd90"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Controller Manager service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Kubernetes Scheduler Pod Specification File\nThe Kubernetes Specification file contains information about the configuration of the\nKubernetes scheduler that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_kube_scheduler","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/kube-scheduler-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/kube-scheduler-pod.yaml\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-kube-scheduler"},"creationTimestamp":"2021-06-03T17:09:36Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:36Z"}],"name":"ocp4-cis-node-master-file-groupowner-kube-scheduler","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693093","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-kube-scheduler","uid":"74eb99c8-df18-4009-8674-e09f44fefebd"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Scheduler service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Kubelet Configuration File\nThe kubelet configuration file contains information about the configuration of the\nOpenShift node that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_kubelet_conf","instructions":"To check the group ownership of /etc/kubernetes/kubelet.conf,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/kubelet.conf\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-kubelet-conf"},"creationTimestamp":"2021-06-03T17:09:29Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:29Z"}],"name":"ocp4-cis-node-master-file-groupowner-kubelet-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692925","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-kubelet-conf","uid":"680480aa-e207-4c1f-b565-4895841c5b18"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The OpenShift Admin Kubeconfig Files\nThere are various kubeconfig files that can be used by the administrator,\ndefining various settings for the administration of the cluster. These files\ncontain credentials that can be used to control the cluster and are needed\nfor disaster recovery and each kubeconfig points to a different endpoint in\nthe cluster. You should restrict its file permissions to maintain the\nintegrity of the kubeconfig file as an attacker who gains access to these\nfiles can take over the cluster.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_master_admin_kubeconfigs","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/kube-apiserver-certs/secrets/node-kubeconfigs/*.kubeconfig,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/kube-apiserver-certs/secrets/node-kubeconfigs/*.kubeconfig\n  If properly configured, the output should indicate the following group-owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-master-admin-kubeconfigs"},"creationTimestamp":"2021-06-03T17:09:31Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:31Z"}],"name":"ocp4-cis-node-master-file-groupowner-master-admin-kubeconfigs","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692983","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-master-admin-kubeconfigs","uid":"2017c310-3fd0-41da-8de4-5485e072e240"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes API server service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The OpenShift Multus Container Network Interface Plugin Files\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_multus_conf","instructions":"To check the group ownership of /var/run/multus/cni/net.d/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/run/multus/cni/net.d/*\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-multus-conf"},"creationTimestamp":"2021-06-03T17:09:35Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:35Z"}],"name":"ocp4-cis-node-master-file-groupowner-multus-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693080","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-multus-conf","uid":"a99f4796-fb10-4bd3-88d3-f2b0e08b7935"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The OpenShift PKI Certificate Files\nOpenShift makes use of a number of certificates as part of its operation.\nYou should verify the ownership of the directory containing the PKI\ninformation and all files in that directory to maintain their integrity.\nThe directory and files should be owned by the system administrator.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_openshift_pki_cert_files","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/.*/.*/.*/tls.crt,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/.*/.*/.*/tls.crt\n  If properly configured, the output should indicate the following group-owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-openshift-pki-cert-files"},"creationTimestamp":"2021-06-03T17:09:30Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:30Z"}],"name":"ocp4-cis-node-master-file-groupowner-openshift-pki-cert-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692969","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-openshift-pki-cert-files","uid":"1fcff7ec-f921-4c02-91c7-bc86412aae53"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Control Plane.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The OpenShift PKI Private Key Files\nOpenShift makes use of a number of certificates as part of its operation.\nYou should verify the ownership of the directory containing the PKI\ninformation and all files in that directory to maintain their integrity.\nThe directory and files should be owned by root:root.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_openshift_pki_key_files","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/*/*/*/*.key,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/*/*/*/*.key\n  If properly configured, the output should indicate the following group-owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-openshift-pki-key-files"},"creationTimestamp":"2021-06-03T17:09:28Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:28Z"}],"name":"ocp4-cis-node-master-file-groupowner-openshift-pki-key-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692911","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-openshift-pki-key-files","uid":"dec1b971-0984-462c-bc2f-2c1174f97669"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Control Plane.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The OpenShift SDN CNI Server Config\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_openshift_sdn_cniserver_config","instructions":"To check the group ownership of /var/run/openshift-sdn/cniserver/config.json,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/run/openshift-sdn/cniserver/config.json\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-openshift-sdn-cniserver-config"},"creationTimestamp":"2021-06-03T17:09:35Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:35Z"}],"name":"ocp4-cis-node-master-file-groupowner-openshift-sdn-cniserver-config","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693086","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-openshift-sdn-cniserver-config","uid":"f009f4fc-21ca-4ff7-8e5a-5f8e2d37645c"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Open vSwitch Configuration Database\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_ovs_conf_db","instructions":"To check the group ownership of /etc/openvswitch/conf.db,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/openvswitch/conf.db\nIf properly configured, the output should indicate the following group-owner:\nhugetlbfs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-ovs-conf-db"},"creationTimestamp":"2021-06-03T17:09:34Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:34Z"}],"name":"ocp4-cis-node-master-file-groupowner-ovs-conf-db","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693070","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-ovs-conf-db","uid":"d020e93a-371a-4afa-9fdf-dccc05f7502c"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Open vSwitch Configuration Database Lock\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_ovs_conf_db_lock","instructions":"To check the group ownership of /etc/openvswitch/.conf.db.~lock~,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/openvswitch/.conf.db.~lock~\nIf properly configured, the output should indicate the following group-owner:\nhugetlbfs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-ovs-conf-db-lock"},"creationTimestamp":"2021-06-03T17:09:27Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:27Z"}],"name":"ocp4-cis-node-master-file-groupowner-ovs-conf-db-lock","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692900","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-ovs-conf-db-lock","uid":"e7fcff82-347f-4296-a5c0-6ef3006b8827"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Open vSwitch Process ID File\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_ovs_pid","instructions":"To check the group ownership of /var/run/openvswitch/ovs-vswitchd.pid,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/run/openvswitch/ovs-vswitchd.pid\nIf properly configured, the output should indicate the following group-owner:\nopenvswitch","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-ovs-pid"},"creationTimestamp":"2021-06-03T17:09:28Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:28Z"}],"name":"ocp4-cis-node-master-file-groupowner-ovs-pid","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692905","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-ovs-pid","uid":"76dfa313-d058-4c79-b647-7fc263843699"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Open vSwitch Persistent System ID\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_ovs_sys_id_conf","instructions":"To check the group ownership of /etc/openvswitch/system-id.conf,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/openvswitch/system-id.conf\nIf properly configured, the output should indicate the following group-owner:\nhugetlbfs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-ovs-sys-id-conf"},"creationTimestamp":"2021-06-03T17:09:29Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:29Z"}],"name":"ocp4-cis-node-master-file-groupowner-ovs-sys-id-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692949","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-ovs-sys-id-conf","uid":"ad0c9310-67aa-4000-8041-e65068b83b0d"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Open vSwitch Daemon PID File\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_ovs_vswitchd_pid","instructions":"To check the group ownership of /run/openvswitch/ovs-vswitchd.pid,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /run/openvswitch/ovs-vswitchd.pid\nIf properly configured, the output should indicate the following group-owner:\nopenvswitch","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-ovs-vswitchd-pid"},"creationTimestamp":"2021-06-03T17:09:34Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:34Z"}],"name":"ocp4-cis-node-master-file-groupowner-ovs-vswitchd-pid","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693051","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-ovs-vswitchd-pid","uid":"d1d261d4-3a05-463d-b407-250d600b2be2"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Open vSwitch Database Server PID\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_ovsdb_server_pid","instructions":"To check the group ownership of /run/openvswitch/ovsdb-server.pid,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /run/openvswitch/ovsdb-server.pid\nIf properly configured, the output should indicate the following group-owner:\nopenvswitch","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-ovsdb-server-pid"},"creationTimestamp":"2021-06-03T17:09:32Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:32Z"}],"name":"ocp4-cis-node-master-file-groupowner-ovsdb-server-pid","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693000","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-ovsdb-server-pid","uid":"a8bbed68-c6db-4f50-af31-97c06a901349"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Kubernetes Scheduler Kubeconfig File\nThe kubeconfig for the Scheduler contains paramters for the scheduler\nto access the Kube API.\nYou should set its file ownership to maintain the integrity of the file.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_scheduler_kubeconfig","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/configmaps/scheduler-kubeconfig/kubeconfig,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/configmaps/scheduler-kubeconfig/kubeconfig\n  If properly configured, the output should indicate the following group-owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-scheduler-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:27Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:27Z"}],"name":"ocp4-cis-node-master-file-groupowner-scheduler-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692896","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-scheduler-kubeconfig","uid":"966dec6d-4b62-4040-8db7-ee6eec54628c"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Scheduler service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns the Worker Certificate Authority File\nThe worker certificate authority file contains the certificate authority\ncertificate for an OpenShift node that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_worker_ca","instructions":"To check the group ownership of /etc/kubernetes/kubelet-ca.crt,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/kubelet-ca.crt\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-worker-ca"},"creationTimestamp":"2021-06-03T17:09:31Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:31Z"}],"name":"ocp4-cis-node-master-file-groupowner-worker-ca","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692977","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-worker-ca","uid":"03bcf09f-4b47-4ee8-875b-801e11a6fb33"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Worker Kubeconfig File\nThe worker kubeconfig file contains information about the administrative configuration of the\nOpenShift cluster that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_worker_kubeconfig","instructions":"To check the group ownership of /var/lib/kubelet/kubeconfig,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/lib/kubelet/kubeconfig\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-worker-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:32Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:32Z"}],"name":"ocp4-cis-node-master-file-groupowner-worker-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692996","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-worker-kubeconfig","uid":"a6c64d42-4032-4af4-9bbf-5c676b42945d"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The OpenShift Node Service File\nfile contains information about the configuration of the\nOpenShift node service that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_worker_service","instructions":"To check the group ownership of /etc/systemd/system/kubelet.service,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/systemd/system/kubelet.service\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-worker-service"},"creationTimestamp":"2021-06-03T17:09:32Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:32Z"}],"name":"ocp4-cis-node-master-file-groupowner-worker-service","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692994","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-groupowner-worker-service","uid":"e909bcb9-1857-426a-a328-938f76514712"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The OpenShift Container Network Interface Files\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_cni_conf","instructions":"To check the ownership of /etc/cni/net.d/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/cni/net.d/*\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-cni-conf"},"creationTimestamp":"2021-06-03T17:09:29Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:29Z"}],"name":"ocp4-cis-node-master-file-owner-cni-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692929","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-cni-conf","uid":"3f1b8307-0558-4972-af5c-05d74538b303"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The OpenShift Controller Manager Kubeconfig File\nThe Controller Manager's kubeconfig contains information about how the\ncomponent will access the API server. You should set its file ownership to\nmaintain the integrity of the file.","id":"xccdf_org.ssgproject.content_rule_file_owner_controller_manager_kubeconfig","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/configmaps/controller-manager-kubeconfig/kubeconfig,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/configmaps/controller-manager-kubeconfig/kubeconfig\n  If properly configured, the output should indicate the following owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-controller-manager-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:33Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:33Z"}],"name":"ocp4-cis-node-master-file-owner-controller-manager-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693012","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-controller-manager-kubeconfig","uid":"3a9cf22f-ee0f-42ca-a242-060041c34565"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Controller Manager service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Etcd Database Directory\netcd is a highly-available key-value store used by Kubernetes deployments for\npersistent storage of all of its REST API objects. This data directory should\nbe protected from any unauthorized reads or writes.","id":"xccdf_org.ssgproject.content_rule_file_owner_etcd_data_dir","instructions":"To check the ownership of /var/lib/etcd/member/,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/lib/etcd/member/\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-etcd-data-dir"},"creationTimestamp":"2021-06-03T17:09:29Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:29Z"}],"name":"ocp4-cis-node-master-file-owner-etcd-data-dir","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692951","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-etcd-data-dir","uid":"a75a1f47-8a34-438d-bc8f-eb00c20cb2d8"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Etcd Write-Ahead-Log Files\netcd is a highly-available key-value store used by Kubernetes deployments for\npersistent storage of all of its REST API objects. This data directory should\nbe protected from any unauthorized reads or writes.","id":"xccdf_org.ssgproject.content_rule_file_owner_etcd_data_files","instructions":"To check the ownership of /var/lib/etcd/member/wal/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/lib/etcd/member/wal/*\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-etcd-data-files"},"creationTimestamp":"2021-06-03T17:09:33Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:33Z"}],"name":"ocp4-cis-node-master-file-owner-etcd-data-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693025","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-etcd-data-files","uid":"782192fd-6db4-476c-8535-8b80033c6ab8"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Etcd Member Pod Specification File\nThe etcd pod specification file controls various parameters that\nset the behavior of the etcd service in the master node. etcd is a\nhighly-available key-value store which Kubernetes uses for persistent\nstorage of all of its REST API object. You should restrict its file\npermissions to maintain the integrity of the file. The file should be\nwritable by only the administrators on the system.","id":"xccdf_org.ssgproject.content_rule_file_owner_etcd_member","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/etcd-pod-*/etcd-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/static-pod-resources/etcd-pod-*/etcd-pod.yaml\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-etcd-member"},"creationTimestamp":"2021-06-03T17:09:33Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:33Z"}],"name":"ocp4-cis-node-master-file-owner-etcd-member","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693013","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-etcd-member","uid":"c9bd795c-c6e6-4a7e-a24d-7417311cf679"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Etcd PKI Certificate Files\nOpenShift makes use of a number of certificates as part of its operation.\nYou should verify the ownership of the directory containing the PKI\ninformation and all files in that directory to maintain their integrity.\nThe directory and files should be owned by the system administrator.","id":"xccdf_org.ssgproject.content_rule_file_owner_etcd_pki_cert_files","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/*/*/*/*.crt,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/*/*/*/*.crt\n  If properly configured, the output should indicate the following owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-etcd-pki-cert-files"},"creationTimestamp":"2021-06-03T17:09:34Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:34Z"}],"name":"ocp4-cis-node-master-file-owner-etcd-pki-cert-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693048","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-etcd-pki-cert-files","uid":"89d1227d-8bfa-441b-b4af-3e3b4e3b8059"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The OpenShift SDN Container Network Interface Plugin IP Address Allocations\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_ip_allocations","instructions":"To check the ownership of /var/lib/cni/networks/openshift-sdn/.*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/lib/cni/networks/openshift-sdn/.*\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-ip-allocations"},"creationTimestamp":"2021-06-03T17:09:28Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:28Z"}],"name":"ocp4-cis-node-master-file-owner-ip-allocations","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692917","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-ip-allocations","uid":"429ab4a1-fcac-4441-aa6f-c5ffa6b61938"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Kubernetes API Server Pod Specification File\nThe Kubernetes specification file contains information about the configuration of the\nKubernetes API Server that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_owner_kube_apiserver","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/kube-apiserver-pod-*/kube-apiserver-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/static-pod-resources/kube-apiserver-pod-*/kube-apiserver-pod.yaml\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-kube-apiserver"},"creationTimestamp":"2021-06-03T17:09:35Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:35Z"}],"name":"ocp4-cis-node-master-file-owner-kube-apiserver","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693076","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-kube-apiserver","uid":"ee739323-556f-4253-bcdb-96e7d084ea1f"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes API Server service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Kubernetes Controller Manager Pod Specificiation File\nThe Kubernetes specification file contains information about the configuration of the\nKubernetes Controller Manager Server that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_owner_kube_controller_manager","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/kube-controller-manager-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/kube-controller-manager-pod.yaml\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-kube-controller-manager"},"creationTimestamp":"2021-06-03T17:09:36Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:36Z"}],"name":"ocp4-cis-node-master-file-owner-kube-controller-manager","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693092","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-kube-controller-manager","uid":"2cb02d96-8e40-48f5-be12-24c25baf7389"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Controller Manager service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Kubernetes Scheduler Pod Specification File\nThe Kubernetes specification file contains information about the configuration of the\nKubernetes scheduler that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_owner_kube_scheduler","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/kube-scheduler-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/kube-scheduler-pod.yaml\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-kube-scheduler"},"creationTimestamp":"2021-06-03T17:09:29Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:29Z"}],"name":"ocp4-cis-node-master-file-owner-kube-scheduler","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692931","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-kube-scheduler","uid":"78be800f-299d-4be7-bdc1-9329d420f8ff"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Scheduler service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Kubelet Configuration File\nThe kubelet configuration file contains information about the configuration of the\nOpenShift node that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_owner_kubelet_conf","instructions":"To check the ownership of /etc/kubernetes/kubelet.conf,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/kubelet.conf\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-kubelet-conf"},"creationTimestamp":"2021-06-03T17:09:30Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:30Z"}],"name":"ocp4-cis-node-master-file-owner-kubelet-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692953","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-kubelet-conf","uid":"79ea67d6-1eb5-46ef-8fd4-2c0ac9e07cff"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The OpenShift Admin Kubeconfig Files\nThere are various kubeconfig files that can be used by the administrator,\ndefining various settings for the administration of the cluster. These files\ncontain credentials that can be used to control the cluster and are needed\nfor disaster recovery and each kubeconfig points to a different endpoint in\nthe cluster. You should restrict its file permissions to maintain the\nintegrity of the kubeconfig file as an attacker who gains access to these\nfiles can take over the cluster.","id":"xccdf_org.ssgproject.content_rule_file_owner_master_admin_kubeconfigs","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/kube-apiserver-certs/secrets/node-kubeconfigs/*.kubeconfig,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/kube-apiserver-certs/secrets/node-kubeconfigs/*.kubeconfig\n  If properly configured, the output should indicate the following owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-master-admin-kubeconfigs"},"creationTimestamp":"2021-06-03T17:09:28Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:28Z"}],"name":"ocp4-cis-node-master-file-owner-master-admin-kubeconfigs","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692921","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-master-admin-kubeconfigs","uid":"68a8a0f9-d385-4992-aadf-381f25f18b1a"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Control Plane.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The OpenShift Multus Container Network Interface Plugin Files\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_multus_conf","instructions":"To check the ownership of /var/run/multus/cni/net.d/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/run/multus/cni/net.d/*\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-multus-conf"},"creationTimestamp":"2021-06-03T17:09:35Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:35Z"}],"name":"ocp4-cis-node-master-file-owner-multus-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693078","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-multus-conf","uid":"a818fb96-dfa8-426a-b28b-05d7f0953ce5"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The OpenShift PKI Certificate Files\nOpenShift makes use of a number of certificates as part of its operation.\nYou should verify the ownership of the directory containing the PKI\ninformation and all files in that directory to maintain their integrity.","id":"xccdf_org.ssgproject.content_rule_file_owner_openshift_pki_cert_files","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/*/*/*/tls.crt,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/*/*/*/tls.crt\n  If properly configured, the output should indicate the following owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-openshift-pki-cert-files"},"creationTimestamp":"2021-06-03T17:09:31Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:31Z"}],"name":"ocp4-cis-node-master-file-owner-openshift-pki-cert-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692979","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-openshift-pki-cert-files","uid":"665643c9-fbda-4f2a-962c-49e758ef0f03"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Control Plane.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The OpenShift PKI Private Key Files\nOpenShift makes use of a number of certificates as part of its operation.\nYou should verify the ownership of the directory containing the PKI\ninformation and all files in that directory to maintain their integrity.\nThe directory and files should be owned by root:root.","id":"xccdf_org.ssgproject.content_rule_file_owner_openshift_pki_key_files","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/*/*/*/*.key,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/*/*/*/*.key\n  If properly configured, the output should indicate the following owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-openshift-pki-key-files"},"creationTimestamp":"2021-06-03T17:09:33Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:33Z"}],"name":"ocp4-cis-node-master-file-owner-openshift-pki-key-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693006","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-openshift-pki-key-files","uid":"0a2d5da3-8b18-4641-8967-3bef9da56405"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Control Plane.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The OpenShift SDN CNI Server Config\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_openshift_sdn_cniserver_config","instructions":"To check the ownership of /var/run/openshift-sdn/cniserver/config.json,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/run/openshift-sdn/cniserver/config.json\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-openshift-sdn-cniserver-config"},"creationTimestamp":"2021-06-03T17:09:27Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:27Z"}],"name":"ocp4-cis-node-master-file-owner-openshift-sdn-cniserver-config","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692897","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-openshift-sdn-cniserver-config","uid":"e9992d72-db3a-4c9d-97a4-5b1ad43d7afc"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Open vSwitch Configuration Database\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_ovs_conf_db","instructions":"To check the ownership of /etc/openvswitch/conf.db,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/openvswitch/conf.db\nIf properly configured, the output should indicate the following owner:\nopenvswitch","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-ovs-conf-db"},"creationTimestamp":"2021-06-03T17:09:27Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:27Z"}],"name":"ocp4-cis-node-master-file-owner-ovs-conf-db","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692901","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-ovs-conf-db","uid":"67014368-3330-4493-8544-c4444a18bf1b"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Open vSwitch Configuration Database Lock\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_ovs_conf_db_lock","instructions":"To check the ownership of /etc/openvswitch/.conf.db.~lock~,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/openvswitch/.conf.db.~lock~\nIf properly configured, the output should indicate the following owner:\nopenvswitch","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-ovs-conf-db-lock"},"creationTimestamp":"2021-06-03T17:09:32Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:32Z"}],"name":"ocp4-cis-node-master-file-owner-ovs-conf-db-lock","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693004","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-ovs-conf-db-lock","uid":"686646b3-6d6e-4fba-96d6-3bbf2a9a2282"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Open vSwitch Process ID File\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_ovs_pid","instructions":"To check the ownership of /var/run/openvswitch/ovs-vswitchd.pid,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/run/openvswitch/ovs-vswitchd.pid\nIf properly configured, the output should indicate the following owner:\nopenvswitch","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-ovs-pid"},"creationTimestamp":"2021-06-03T17:09:31Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:31Z"}],"name":"ocp4-cis-node-master-file-owner-ovs-pid","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692986","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-ovs-pid","uid":"ce91bd26-2130-4b32-8312-ed07e1cbfc05"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Open vSwitch Persistent System ID\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_ovs_sys_id_conf","instructions":"To check the ownership of /etc/openvswitch/system-id.conf,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/openvswitch/system-id.conf\nIf properly configured, the output should indicate the following owner:\nopenvswitch","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-ovs-sys-id-conf"},"creationTimestamp":"2021-06-03T17:09:27Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:27Z"}],"name":"ocp4-cis-node-master-file-owner-ovs-sys-id-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692898","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-ovs-sys-id-conf","uid":"b2ef47f3-6f06-46f8-bf52-26939ccd4714"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Open vSwitch Daemon PID File\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_ovs_vswitchd_pid","instructions":"To check the ownership of /run/openvswitch/ovs-vswitchd.pid,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /run/openvswitch/ovs-vswitchd.pid\nIf properly configured, the output should indicate the following owner:\nopenvswitch","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-ovs-vswitchd-pid"},"creationTimestamp":"2021-06-03T17:09:34Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:34Z"}],"name":"ocp4-cis-node-master-file-owner-ovs-vswitchd-pid","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693052","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-ovs-vswitchd-pid","uid":"ea0d3b73-99d3-438e-ac26-b625c11935d7"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Open vSwitch Database Server PID\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_ovsdb_server_pid","instructions":"To check the ownership of /run/openvswitch/ovsdb-server.pid,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /run/openvswitch/ovsdb-server.pid\nIf properly configured, the output should indicate the following owner:\nopenvswitch","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-ovsdb-server-pid"},"creationTimestamp":"2021-06-03T17:09:36Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:36Z"}],"name":"ocp4-cis-node-master-file-owner-ovsdb-server-pid","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693087","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-ovsdb-server-pid","uid":"851bddfe-d447-49c0-a753-df2e0acf66b7"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Kubernetes Scheduler Kubeconfig File\nThe kubeconfig for the Scheduler contains paramters for the scheduler\nto access the Kube API.\nYou should set its file ownership to maintain the integrity of the file.","id":"xccdf_org.ssgproject.content_rule_file_owner_scheduler_kubeconfig","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/configmaps/scheduler-kubeconfig/kubeconfig,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/configmaps/scheduler-kubeconfig/kubeconfig\n  If properly configured, the output should indicate the following owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-scheduler-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:33Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:33Z"}],"name":"ocp4-cis-node-master-file-owner-scheduler-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693011","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-scheduler-kubeconfig","uid":"3e50e82f-52b5-41a8-9b65-b314254c7fbb"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Scheduler service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns the Worker Certificate Authority File\nThe worker certificate authority file contains the certificate authority\ncertificate for an OpenShift node that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_owner_worker_ca","instructions":"To check the ownership of /etc/kubernetes/kubelet-ca.crt,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/kubelet-ca.crt\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-worker-ca"},"creationTimestamp":"2021-06-03T17:09:30Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:30Z"}],"name":"ocp4-cis-node-master-file-owner-worker-ca","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692971","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-worker-ca","uid":"57c01c1c-8d4e-4a6c-9734-45cad3bbdcff"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Worker Kubeconfig File\nThe worker kubeconfig file contains information about the administrative configuration of the\nOpenShift cluster that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_owner_worker_kubeconfig","instructions":"To check the ownership of /var/lib/kubelet/kubeconfig,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/lib/kubelet/kubeconfig\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-worker-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:28Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:28Z"}],"name":"ocp4-cis-node-master-file-owner-worker-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692922","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-worker-kubeconfig","uid":"104b6d81-15a4-4e3b-86e2-ba336ae5513d"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The OpenShift Node Service File\nfile contains information about the configuration of the\nOpenShift node service that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_owner_worker_service","instructions":"To check the ownership of /etc/systemd/system/kubelet.service,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/systemd/system/kubelet.service\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-worker-service"},"creationTimestamp":"2021-06-03T17:09:35Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:35Z"}],"name":"ocp4-cis-node-master-file-owner-worker-service","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693081","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-owner-worker-service","uid":"10754f6e-b202-4950-8d52-d2c23452249c"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the OpenShift Container Network Interface Files\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_permissions_cni_conf","instructions":"To check the permissions of /etc/cni/net.d/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/cni/net.d/*\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-cni-conf"},"creationTimestamp":"2021-06-03T17:09:28Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:28Z"}],"name":"ocp4-cis-node-master-file-permissions-cni-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692915","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-cni-conf","uid":"72fde4e6-ca6c-4aba-982b-c87716036c64"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the OpenShift Controller Manager Kubeconfig File\nThe Controller Manager's kubeconfig contains information about how the\ncomponent will access the API server. You should restrict its file\npermissions to maintain the integrity of the file. The file should be\nwritable by only the administrators on the system.","id":"xccdf_org.ssgproject.content_rule_file_permissions_controller_manager_kubeconfig","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/configmaps/controller-manager-kubeconfig/kubeconfig,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -l /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/configmaps/controller-manager-kubeconfig/kubeconfig\n  If properly configured, the output should indicate the following permissions:\n  -rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-controller-manager-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:30Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:30Z"}],"name":"ocp4-cis-node-master-file-permissions-controller-manager-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692963","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-controller-manager-kubeconfig","uid":"e7e4da2a-b955-4a2f-a86a-7d8340fe0017"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Controller Manager service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Etcd Database Directory\netcd is a highly-available key-value store used by Kubernetes deployments for persistent\nstorage of all of its REST API objects. This data directory should be protected from any\nunauthorized reads or writes. It should not be readable or writable by any group members\nor the world.","id":"xccdf_org.ssgproject.content_rule_file_permissions_etcd_data_dir","instructions":"To check the permissions of /var/lib/etcd,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /var/lib/etcd\nIf properly configured, the output should indicate the following permissions:\ndrwx------","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-etcd-data-dir"},"creationTimestamp":"2021-06-03T17:09:33Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:33Z"}],"name":"ocp4-cis-node-master-file-permissions-etcd-data-dir","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693010","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-etcd-data-dir","uid":"1d58d834-6b42-4505-9070-36530f106918"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Etcd Write-Ahead-Log Files\netcd is a highly-available key-value store used by Kubernetes deployments for persistent\nstorage of all of its REST API objects. This data directory should be protected from any\nunauthorized reads or writes. It should not be readable or writable by any group members\nor the world.","id":"xccdf_org.ssgproject.content_rule_file_permissions_etcd_data_files","instructions":"To check the permissions of /var/lib/etcd/member/wal/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /var/lib/etcd/member/wal/*\nIf properly configured, the output should indicate the following permissions:\n-rw-------","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-etcd-data-files"},"creationTimestamp":"2021-06-03T17:09:28Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:28Z"}],"name":"ocp4-cis-node-master-file-permissions-etcd-data-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692910","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-etcd-data-files","uid":"dcc0b969-32f1-4dae-85c4-d9eeb2ae8c5f"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Etcd Member Pod Specification File\nThe etcd pod specification file controls various parameters that\nset the behavior of the etcd service in the master node. etcd is a\nhighly-available key-value store which Kubernetes uses for persistent\nstorage of all of its REST API object. You should restrict its file\npermissions to maintain the integrity of the file. The file should be\nwritable by only the administrators on the system.","id":"xccdf_org.ssgproject.content_rule_file_permissions_etcd_member","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/etcd-pod-*/etcd-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/kubernetes/static-pod-resources/etcd-pod-*/etcd-pod.yaml\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-etcd-member"},"creationTimestamp":"2021-06-03T17:09:32Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:32Z"}],"name":"ocp4-cis-node-master-file-permissions-etcd-member","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693001","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-etcd-member","uid":"f78d2d1a-e5fc-410d-978a-a9bea4b9465e"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Etcd PKI Certificate Files\nor more restrictive to protect their integrity.","id":"xccdf_org.ssgproject.content_rule_file_permissions_etcd_pki_cert_files","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/etcd-*/secrets/*/*.crt,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -l /etc/kubernetes/static-pod-resources/etcd-*/secrets/*/*.crt\n  If properly configured, the output should indicate the following permissions:\n  -rw-------","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-etcd-pki-cert-files"},"creationTimestamp":"2021-06-03T17:09:33Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:33Z"}],"name":"ocp4-cis-node-master-file-permissions-etcd-pki-cert-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693039","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-etcd-pki-cert-files","uid":"e61c2376-c225-4895-8c75-ce587758d084"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the OpenShift SDN Container Network Interface Plugin IP Address Allocations\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_permissions_ip_allocations","instructions":"To check the permissions of /var/lib/cni/networks/openshift-sdn/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /var/lib/cni/networks/openshift-sdn/*\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-ip-allocations"},"creationTimestamp":"2021-06-03T17:09:27Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:27Z"}],"name":"ocp4-cis-node-master-file-permissions-ip-allocations","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692902","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-ip-allocations","uid":"b3c481fc-5d7e-44bf-b89a-8f47577f8033"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Kubernetes API Server Pod Specification File\nIf the Kubernetes specification file is writable by a group-owner or the\nworld the risk of its compromise is increased. The file contains the configuration of\nthe Kubernetes API server that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_permissions_kube_apiserver","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/kube-apiserver-pod-*/kube-apiserver-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/kubernetes/static-pod-resources/kube-apiserver-pod-*/kube-apiserver-pod.yaml\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-kube-apiserver"},"creationTimestamp":"2021-06-03T17:09:28Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:28Z"}],"name":"ocp4-cis-node-master-file-permissions-kube-apiserver","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692920","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-kube-apiserver","uid":"438137b7-fbe6-469c-89d7-5fdf65b6e91d"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes API Server service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Kubernetes Controller Manager Pod Specificiation File\nIf the Kubernetes specification file is writable by a group-owner or the\nworld the risk of its compromise is increased. The file contains the configuration of\nan Kubernetes Controller Manager server that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_permissions_kube_controller_manager","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/kube-controller-manager-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/kube-controller-manager-pod.yaml\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-kube-controller-manager"},"creationTimestamp":"2021-06-03T17:09:31Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:31Z"}],"name":"ocp4-cis-node-master-file-permissions-kube-controller-manager","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692980","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-kube-controller-manager","uid":"865190ca-6c15-4955-87af-2178e2a7078e"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Controller Manager service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on The Kubelet Configuration File\nIf the kubelet configuration file is writable by a group-owner or the\nworld the risk of its compromise is increased. The file contains the configuration of\nan OpenShift node that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_permissions_kubelet_conf","instructions":"To check the permissions of /etc/kubernetes/kubelet.conf,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/kubernetes/kubelet.conf\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-kubelet-conf"},"creationTimestamp":"2021-06-03T17:09:29Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:29Z"}],"name":"ocp4-cis-node-master-file-permissions-kubelet-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692932","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-kubelet-conf","uid":"59353eae-78bf-4d4f-a06b-690bdae2d4be"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the OpenShift Admin Kubeconfig Files\nThere are various kubeconfig files that can be used by the administrator,\ndefining various settings for the administration of the cluster. These files\ncontain credentials that can be used to control the cluster and are needed\nfor disaster recovery and each kubeconfig points to a different endpoint in\nthe cluster. You should restrict its file permissions to maintain the\nintegrity of the kubeconfig file as an attacker who gains access to these\nfiles can take over the cluster.","id":"xccdf_org.ssgproject.content_rule_file_permissions_master_admin_kubeconfigs","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/kube-apiserver-certs/secrets/node-kubeconfigs/*.kubeconfig,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -l /etc/kubernetes/static-pod-resources/kube-apiserver-certs/secrets/node-kubeconfigs/*.kubeconfig\n  If properly configured, the output should indicate the following permissions:\n  -rw-------","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-master-admin-kubeconfigs"},"creationTimestamp":"2021-06-03T17:09:30Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:30Z"}],"name":"ocp4-cis-node-master-file-permissions-master-admin-kubeconfigs","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692968","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-master-admin-kubeconfigs","uid":"c6bb3770-3b75-4dde-83a2-5da27aa466a1"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Control Plane.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the OpenShift Multus Container Network Interface Plugin Files\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_permissions_multus_conf","instructions":"To check the permissions of /var/run/multus/cni/net.d/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /var/run/multus/cni/net.d/*\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-multus-conf"},"creationTimestamp":"2021-06-03T17:09:33Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:33Z"}],"name":"ocp4-cis-node-master-file-permissions-multus-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693005","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-multus-conf","uid":"586a1268-4066-4d8e-b4af-fb49b58634cf"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the OpenShift PKI Certificate Files\nor more restrictive to protect their integrity.","id":"xccdf_org.ssgproject.content_rule_file_permissions_openshift_pki_cert_files","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/kube-*/secrets/*/tls.crt,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -l /etc/kubernetes/static-pod-resources/kube-*/secrets/*/tls.crt\n  If properly configured, the output should indicate the following permissions:\n  -rw-------","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-openshift-pki-cert-files"},"creationTimestamp":"2021-06-03T17:09:28Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:28Z"}],"name":"ocp4-cis-node-master-file-permissions-openshift-pki-cert-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692909","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-openshift-pki-cert-files","uid":"aa73d5bc-1c64-4f67-bcd4-192114a96c88"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Control Plane.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the OpenShift PKI Private Key Files\nto protect their integrity and confidentiality.","id":"xccdf_org.ssgproject.content_rule_file_permissions_openshift_pki_key_files","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/*/*/*/*.key,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -l /etc/kubernetes/static-pod-resources/*/*/*/*.key\n  If properly configured, the output should indicate the following permissions:\n  -rw-------","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-openshift-pki-key-files"},"creationTimestamp":"2021-06-03T17:09:32Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:32Z"}],"name":"ocp4-cis-node-master-file-permissions-openshift-pki-key-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692998","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-openshift-pki-key-files","uid":"e33903a1-622d-4956-a2df-fdae56e383b3"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Control Plane.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Open vSwitch Configuration Database\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_permissions_ovs_conf_db","instructions":"To check the permissions of /etc/openvswitch/conf.db,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/openvswitch/conf.db\nIf properly configured, the output should indicate the following permissions:\n-rw-r-----","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-ovs-conf-db"},"creationTimestamp":"2021-06-03T17:09:32Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:32Z"}],"name":"ocp4-cis-node-master-file-permissions-ovs-conf-db","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693002","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-ovs-conf-db","uid":"85bde7ab-f7c0-4071-9727-dd1efeec6a96"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Open vSwitch Configuration Database Lock\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_permissions_ovs_conf_db_lock","instructions":"To check the permissions of /etc/openvswitch/.conf.db.~lock~,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/openvswitch/.conf.db.~lock~\nIf properly configured, the output should indicate the following permissions:\n-rw-------","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-ovs-conf-db-lock"},"creationTimestamp":"2021-06-03T17:09:28Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:28Z"}],"name":"ocp4-cis-node-master-file-permissions-ovs-conf-db-lock","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692907","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-ovs-conf-db-lock","uid":"8007a016-0e31-447e-a5f3-238286f2f201"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Open vSwitch Process ID File\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_permissions_ovs_pid","instructions":"To check the permissions of /var/run/openvswitch/ovs-vswitchd.pid,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /var/run/openvswitch/ovs-vswitchd.pid\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-ovs-pid"},"creationTimestamp":"2021-06-03T17:09:32Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:32Z"}],"name":"ocp4-cis-node-master-file-permissions-ovs-pid","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692999","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-ovs-pid","uid":"adcb2dd1-24fc-4fdd-a144-46b35ff53563"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Open vSwitch Persistent System ID\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_permissions_ovs_sys_id_conf","instructions":"To check the permissions of /etc/openvswitch/system-id.conf,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/openvswitch/system-id.conf\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-ovs-sys-id-conf"},"creationTimestamp":"2021-06-03T17:09:35Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:35Z"}],"name":"ocp4-cis-node-master-file-permissions-ovs-sys-id-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693074","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-ovs-sys-id-conf","uid":"f23a1f1e-3482-4ec2-ab02-c9520bceee5f"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Open vSwitch Daemon PID File\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_permissions_ovs_vswitchd_pid","instructions":"To check the permissions of /run/openvswitch/ovs-vswitchd.pid,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /run/openvswitch/ovs-vswitchd.pid\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-ovs-vswitchd-pid"},"creationTimestamp":"2021-06-03T17:09:29Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:29Z"}],"name":"ocp4-cis-node-master-file-permissions-ovs-vswitchd-pid","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692950","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-ovs-vswitchd-pid","uid":"8d6a1e97-9f43-43e8-802f-1692eadf3a0c"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Open vSwitch Database Server PID\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_permissions_ovsdb_server_pid","instructions":"To check the permissions of /run/openvswitch/ovsdb-server.pid,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /run/openvswitch/ovsdb-server.pid\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-ovsdb-server-pid"},"creationTimestamp":"2021-06-03T17:09:33Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:33Z"}],"name":"ocp4-cis-node-master-file-permissions-ovsdb-server-pid","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693009","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-ovsdb-server-pid","uid":"beb5a398-0f0f-4821-8ea9-d70bca74eb20"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Kubernetes Scheduler Pod Specification File\nIf the Kubernetes specification file is writable by a group-owner or the\nworld the risk of its compromise is increased. The file contains the configuration of\nan Kubernetes Scheduler service that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_permissions_scheduler","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/kube-scheduler-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/kube-scheduler-pod.yaml\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-scheduler"},"creationTimestamp":"2021-06-03T17:09:28Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:28Z"}],"name":"ocp4-cis-node-master-file-permissions-scheduler","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692908","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-scheduler","uid":"35b86a99-d522-40b0-9158-92a737e265c3"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Scheduler service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Kubernetes Scheduler Kubeconfig File\nThe kubeconfig for the Scheduler contains paramters for the scheduler\nto access the Kube API. You should restrict its file permissions to maintain\nthe integrity of the file. The file should be writable by only the\nadministrators on the system.","id":"xccdf_org.ssgproject.content_rule_file_permissions_scheduler_kubeconfig","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/configmaps/scheduler-kubeconfig/kubeconfig,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -l /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/configmaps/scheduler-kubeconfig/kubeconfig\n  If properly configured, the output should indicate the following permissions:\n  -rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-scheduler-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:29Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:29Z"}],"name":"ocp4-cis-node-master-file-permissions-scheduler-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692952","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-scheduler-kubeconfig","uid":"691daf09-13ce-4d6d-b782-373e26e632fc"},"severity":"medium","status":"PASS","warnings":["This rule is only applicable for nodes that run the Kubernetes Scheduler service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Worker Certificate Authority File\nIf the worker certificate authority file is writable by a group-owner or the\nworld the risk of its compromise is increased. The file contains the certificate authority\ncertificate for an OpenShift node that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_permissions_worker_ca","instructions":"To check the permissions of /etc/kubernetes/kubelet-ca.crt,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/kubernetes/kubelet-ca.crt\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-worker-ca"},"creationTimestamp":"2021-06-03T17:09:32Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:32Z"}],"name":"ocp4-cis-node-master-file-permissions-worker-ca","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692995","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-worker-ca","uid":"e74c3f53-6afd-4ab0-8d47-547ad6e9bcad"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Worker Kubeconfig File\nIf the worker kubeconfig file is writable by a group-owner or the\nworld the risk of its compromise is increased. The file contains the administration configuration of the\nOpenShift cluster that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_permissions_worker_kubeconfig","instructions":"To check the permissions of /var/lib/kubelet/kubeconfig,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /var/lib/kubelet/kubeconfig\nIf properly configured, the output should indicate the following permissions:\n-rw-------","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-worker-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:36Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:36Z"}],"name":"ocp4-cis-node-master-file-permissions-worker-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693094","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-worker-kubeconfig","uid":"b7c00e7e-ab2c-4c64-b7d6-e6a0c2801522"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the OpenShift Node Service File\nfile is writable by a group-owner or the\nworld the risk of its compromise is increased. The file contains the service configuration of the\nOpenShift node service that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_permissions_worker_service","instructions":"To check the permissions of /etc/systemd/system/kubelet.service,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -l /etc/systemd/system/kubelet.service\n  If properly configured, the output should indicate the following permissions:\n  -rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-worker-service"},"creationTimestamp":"2021-06-03T17:09:32Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:32Z"}],"name":"ocp4-cis-node-master-file-permissions-worker-service","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692990","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-permissions-worker-service","uid":"7fe2e8c4-14da-409c-bd9f-4cfce4dd2e7f"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the OpenShift SDN CNI Server Config\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_perms_openshift_sdn_cniserver_config","instructions":"To check the permissions of /var/run/openshift-sdn/cniserver/config.json,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /var/run/openshift-sdn/cniserver/config.json\nIf properly configured, the output should indicate the following permissions:\n-r--r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-perms-openshift-sdn-cniserver-config"},"creationTimestamp":"2021-06-03T17:09:28Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:28Z"}],"name":"ocp4-cis-node-master-file-perms-openshift-sdn-cniserver-config","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692919","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-file-perms-openshift-sdn-cniserver-config","uid":"aa204aae-72f3-4362-84f8-f7b2a2bd0fa9"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Disable Anonymous Authentication to the Kubelet\nWhen enabled, requests that are not rejected by other configured\nauthentication methods are treated as anonymous requests. These\nrequests are then served by the Kubelet server. OpenShift Operators should\nrely on authentication to authorize access and disallow anonymous\nrequests.","id":"xccdf_org.ssgproject.content_rule_kubelet_anonymous_auth","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep -A1 anonymous /etc/kubernetes/kubelet.conf\nThe output should return enabled: false.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-anonymous-auth"},"creationTimestamp":"2021-06-03T17:09:35Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:35Z"}],"name":"ocp4-cis-node-master-kubelet-anonymous-auth","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693082","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-anonymous-auth","uid":"b1e1bc7a-6adf-4259-88bd-8ebc06436e8a"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure authorization is set to Webhook\nEnsuring that the authorization is configured correctly helps enforce that\nunauthenticated/unauthorized users have no access to OpenShift nodes.","id":"xccdf_org.ssgproject.content_rule_kubelet_authorization_mode","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep -A1 authorization /etc/kubernetes/kubelet.conf\nVerify that the output is not set to mode: AlwaysAllow, or missing\n(defaults to mode: Webhook).","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-authorization-mode"},"creationTimestamp":"2021-06-03T17:09:28Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:28Z"}],"name":"ocp4-cis-node-master-kubelet-authorization-mode","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692913","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-authorization-mode","uid":"0372b523-973b-49bf-b3c9-4ddd2226b794"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"kubelet - Configure the Client CA Certificate\nNot having a CA certificate for the kubelet will subject the kubelet to possible\nman-in-the-middle attacks especially on unsafe or untrusted networks.\nCertificate validation for the kubelet allows the API server to validate\nthe kubelet's identity.","id":"xccdf_org.ssgproject.content_rule_kubelet_configure_client_ca","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep -A1 x509 /etc/kubernetes/kubelet.conf\nThe output should contain a configured certificate like /etc/kubernetes/kubelet-ca.crt.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-configure-client-ca"},"creationTimestamp":"2021-06-03T17:09:29Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:29Z"}],"name":"ocp4-cis-node-master-kubelet-configure-client-ca","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692936","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-configure-client-ca","uid":"36173609-2241-4bfe-b176-add13661fadd"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Kubelet - Ensure Event Creation Is Configured\nIt is important to capture all events and not restrict event creation.\nEvents are an important source of security information and analytics that\nensure that your environment is consistently monitored using the event\ndata.","id":"xccdf_org.ssgproject.content_rule_kubelet_configure_event_creation","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep eventRecordQPS /etc/kubernetes/kubelet.conf\nThe output should return .","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-configure-event-creation"},"creationTimestamp":"2021-06-03T17:09:30Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:30Z"}],"name":"ocp4-cis-node-master-kubelet-configure-event-creation","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692956","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-configure-event-creation","uid":"9b20e190-12fc-4928-9821-b3d0b48d175e"},"severity":"medium","status":"FAIL","warnings":["object."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure that the Kubelet only makes use of Strong Cryptographic Ciphers\nTLS ciphers have had a number of known vulnerabilities and weaknesses,\nwhich can reduce the protection provided by them. By default Kubernetes\nsupports a number of TLS ciphersuites including some that have security\nconcerns, weakening the protection provided.","id":"xccdf_org.ssgproject.content_rule_kubelet_configure_tls_cipher_suites","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep tlsCipherSuites /etc/kubernetes/kubelet.conf\nVerify that the set of ciphers contains only the following:\n\nTLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,\nTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,\nTLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,\nTLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-configure-tls-cipher-suites"},"creationTimestamp":"2021-06-03T17:09:31Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:31Z"}],"name":"ocp4-cis-node-master-kubelet-configure-tls-cipher-suites","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692987","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-configure-tls-cipher-suites","uid":"e93a5bde-7d77-40b4-a240-5b578d1e259f"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"kubelet - Disable Hostname Override\nAllowing hostnames to be overrided creates issues around resolving nodes\nin addition to TLS configuration, certificate validation, and log correlation\nand validation.","id":"xccdf_org.ssgproject.content_rule_kubelet_disable_hostname_override","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep hostname-override /etc/systemd/system/kubelet.service\nThe output should return no output.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-disable-hostname-override"},"creationTimestamp":"2021-06-03T17:09:30Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:30Z"}],"name":"ocp4-cis-node-master-kubelet-disable-hostname-override","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692966","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-disable-hostname-override","uid":"2542cb33-fcae-4e2a-af0f-3a8f5741329a"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"kubelet - Enable Certificate Rotation\nAllowing the kubelet to auto-update the certificates ensure that there is no downtime\nin certificate renewal as well as ensures confidentiality and integrity.","id":"xccdf_org.ssgproject.content_rule_kubelet_enable_cert_rotation","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep rotateCertificates /etc/kubernetes/kubelet.conf\nThe output should return true.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-enable-cert-rotation"},"creationTimestamp":"2021-06-03T17:09:36Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:36Z"}],"name":"ocp4-cis-node-master-kubelet-enable-cert-rotation","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693097","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-enable-cert-rotation","uid":"36cf8fc6-08fc-4639-a408-79d938cd43cf"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"kubelet - Enable Client Certificate Rotation\nAllowing the kubelet to auto-update the certificates ensure that there is no downtime\nin certificate renewal as well as ensures confidentiality and integrity.","id":"xccdf_org.ssgproject.content_rule_kubelet_enable_client_cert_rotation","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep RotateKubeletClientCertificate /etc/kubernetes/kubelet.conf\nThe output should return true.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-enable-client-cert-rotation"},"creationTimestamp":"2021-06-03T17:09:31Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:31Z"}],"name":"ocp4-cis-node-master-kubelet-enable-client-cert-rotation","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692973","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-enable-client-cert-rotation","uid":"604f92b3-4463-4482-a105-3ea3a1aa357a"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"kubelet - Allow Automatic Firewall Configuration\nThe kubelet should automatically configure the firewall settings to allow access and\nnetworking traffic through. This ensures that when a pod or container is running that\nthe correct ports are configured as well as removing the ports when a pod or\ncontainer is no longer in existence.","id":"xccdf_org.ssgproject.content_rule_kubelet_enable_iptables_util_chains","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep makeIPTablesUtilChains /etc/kubernetes/kubelet.conf\nThe output should return true.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-enable-iptables-util-chains"},"creationTimestamp":"2021-06-03T17:09:34Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:34Z"}],"name":"ocp4-cis-node-master-kubelet-enable-iptables-util-chains","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693069","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-enable-iptables-util-chains","uid":"594eba28-750f-4343-bf5a-614746383f01"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"kubelet - Enable Protect Kernel Defaults\nKernel parameters are usually tuned and hardened by the system administrators\nbefore putting the systems into production. These parameters protect the\nkernel and the system. Your kubelet kernel defaults that rely on such\nparameters should be appropriately set to match the desired secured system\nstate. Ignoring this could potentially lead to running pods with undesired\nkernel behavior.","id":"xccdf_org.ssgproject.content_rule_kubelet_enable_protect_kernel_defaults","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep protectKernelDefaults /etc/kubernetes/kubelet.conf\nThe output should return true.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-enable-protect-kernel-defaults"},"creationTimestamp":"2021-06-03T17:09:36Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:36Z"}],"name":"ocp4-cis-node-master-kubelet-enable-protect-kernel-defaults","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693095","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-enable-protect-kernel-defaults","uid":"633b946b-1f2d-4763-927f-8273a805309f"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"kubelet - Enable Server Certificate Rotation\nAllowing the kubelet to auto-update the certificates ensure that there is no downtime\nin certificate renewal as well as ensures confidentiality and integrity.","id":"xccdf_org.ssgproject.content_rule_kubelet_enable_server_cert_rotation","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep RotateKubeletServerCertificate /etc/kubernetes/kubelet.conf\nThe output should return true.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-enable-server-cert-rotation"},"creationTimestamp":"2021-06-03T17:09:35Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:35Z"}],"name":"ocp4-cis-node-master-kubelet-enable-server-cert-rotation","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693085","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-enable-server-cert-rotation","uid":"40b22552-c790-4b44-8989-da85fe73d488"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"kubelet - Do Not Disable Streaming Timeouts\nEnsuring connections have timeouts helps to protect against denial-of-service attacks as\nwell as disconnect inactive connections. In addition, setting connections timeouts helps\nto prevent from running out of ephemeral ports.","id":"xccdf_org.ssgproject.content_rule_kubelet_enable_streaming_connections","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep streamingConnectionIdleTimeout /etc/kubernetes/kubelet.conf\nThe output should return .","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-enable-streaming-connections"},"creationTimestamp":"2021-06-03T17:09:30Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:30Z"}],"name":"ocp4-cis-node-master-kubelet-enable-streaming-connections","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692964","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-enable-streaming-connections","uid":"6dd4d186-ac79-43e4-a5d8-73f7c4215a16"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionHard: imagefs.available\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_hard_imagefs_available","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionHard.\"imagefs.available\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-hard-imagefs-available"},"creationTimestamp":"2021-06-03T17:09:28Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:28Z"}],"name":"ocp4-cis-node-master-kubelet-eviction-thresholds-set-hard-imagefs-available","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692914","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-eviction-thresholds-set-hard-imagefs-available","uid":"d4eade0b-1162-41d8-bfed-34a889387335"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionHard: imagefs.inodesFree\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_hard_imagefs_inodesfree","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionHard.\"imagefs.inodesFree\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-hard-imagefs-inodesfree"},"creationTimestamp":"2021-06-03T17:09:27Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:27Z"}],"name":"ocp4-cis-node-master-kubelet-eviction-thresholds-set-hard-imagefs-inodesfree","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692899","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-eviction-thresholds-set-hard-imagefs-inodesfree","uid":"1f2e1438-78d0-4295-b99a-a92e61cdb2cc"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionHard: memory.available\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_hard_memory_available","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionHard.\"memory.available\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-hard-memory-available"},"creationTimestamp":"2021-06-03T17:09:34Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:34Z"}],"name":"ocp4-cis-node-master-kubelet-eviction-thresholds-set-hard-memory-available","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693047","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-eviction-thresholds-set-hard-memory-available","uid":"d123378e-a7f0-4aeb-b2d4-2871cc9d6ad0"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionHard: nodefs.available\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_hard_nodefs_available","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionHard.\"nodefs.available\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-hard-nodefs-available"},"creationTimestamp":"2021-06-03T17:09:35Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:35Z"}],"name":"ocp4-cis-node-master-kubelet-eviction-thresholds-set-hard-nodefs-available","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693084","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-eviction-thresholds-set-hard-nodefs-available","uid":"0e04d160-e667-4399-87f6-c73ab51eae17"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionHard: nodefs.inodesFree\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_hard_nodefs_inodesfree","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionHard.\"nodefs.inodesFree\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-hard-nodefs-inodesfree"},"creationTimestamp":"2021-06-03T17:09:29Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:29Z"}],"name":"ocp4-cis-node-master-kubelet-eviction-thresholds-set-hard-nodefs-inodesfree","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692928","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-eviction-thresholds-set-hard-nodefs-inodesfree","uid":"81b89146-e4c0-4301-842e-a8d5df4c87d3"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionSoft: imagefs.available\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_soft_imagefs_available","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionSoft.\"imagefs.available\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-soft-imagefs-available"},"creationTimestamp":"2021-06-03T17:09:34Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:34Z"}],"name":"ocp4-cis-node-master-kubelet-eviction-thresholds-set-soft-imagefs-available","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693068","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-eviction-thresholds-set-soft-imagefs-available","uid":"8a87828b-212c-421e-b73b-996e40fc728e"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionSoft: imagefs.inodesFree\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_soft_imagefs_inodesfree","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionSoft.\"imagefs.inodesFree\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-soft-imagefs-inodesfree"},"creationTimestamp":"2021-06-03T17:09:31Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:31Z"}],"name":"ocp4-cis-node-master-kubelet-eviction-thresholds-set-soft-imagefs-inodesfree","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692989","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-eviction-thresholds-set-soft-imagefs-inodesfree","uid":"0afcfcff-dc32-4117-9370-be96f0d77cb0"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionSoft: memory.available\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_soft_memory_available","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionSoft.\"memory.available\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-soft-memory-available"},"creationTimestamp":"2021-06-03T17:09:35Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:35Z"}],"name":"ocp4-cis-node-master-kubelet-eviction-thresholds-set-soft-memory-available","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44693083","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-eviction-thresholds-set-soft-memory-available","uid":"a84c19bc-95b1-4744-b7e5-faa9a80b33ff"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionSoft: nodefs.available\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_soft_nodefs_available","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionSoft.\"nodefs.available\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-soft-nodefs-available"},"creationTimestamp":"2021-06-03T17:09:28Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:28Z"}],"name":"ocp4-cis-node-master-kubelet-eviction-thresholds-set-soft-nodefs-available","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692904","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-eviction-thresholds-set-soft-nodefs-available","uid":"2cd093e3-0e81-4c84-99aa-0037c71ceaed"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionSoft: nodefs.inodesFree\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_soft_nodefs_inodesfree","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionSoft.\"nodefs.inodesFree\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-soft-nodefs-inodesfree"},"creationTimestamp":"2021-06-03T17:09:30Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-master","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"33a7f36b-5734-47d5-8d9b-88b3ace56191\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:30Z"}],"name":"ocp4-cis-node-master-kubelet-eviction-thresholds-set-soft-nodefs-inodesfree","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-master","uid":"33a7f36b-5734-47d5-8d9b-88b3ace56191"}],"resourceVersion":"44692972","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-master-kubelet-eviction-thresholds-set-soft-nodefs-inodesfree","uid":"5f2b72ee-315d-4149-8329-b2084b40fe4c"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure A Unique CA Certificate for etcd\nThe Kubernetes API server and etcd utilize separate CA certificates in\nOpenShift.  This ensures that the etcd data is still protected in the event\nthat the API server CA is compromised.","id":"xccdf_org.ssgproject.content_rule_etcd_unique_ca","instructions":"Run the following command:\noc debug node/$NODE -- diff /host/etc/kubernetes/static-pod-resources/etcd-certs/configmaps/etcd-serving-ca/ca-bundle.crt /host/etc/kubernetes/static-pod-resources/kube-apiserver-certs/configmaps/client-ca/ca-bundle.crt\nwhere $NODE is a master node. If you don't see diff output\nthe differences, you might have a compromise and should isolate the cluster.\nOpenShift will use separate PKIs by default.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"etcd-unique-ca"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-node-worker-etcd-unique-ca","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692683","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-etcd-unique-ca","uid":"7ccd33b3-0749-47ec-8445-5748bea449f4"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The OpenShift Container Network Interface Files\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_cni_conf","instructions":"To check the group ownership of /etc/cni/net.d/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/cni/net.d/*\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-cni-conf"},"creationTimestamp":"2021-06-03T17:09:24Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:24Z"}],"name":"ocp4-cis-node-worker-file-groupowner-cni-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692875","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-cni-conf","uid":"962e0dbb-eceb-462a-ad73-0e7bb4e65b64"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The OpenShift Controller Manager Kubeconfig File\nThe Controller Manager's kubeconfig contains information about how the\ncomponent will access the API server. You should set its file ownership to\nmaintain the integrity of the file.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_controller_manager_kubeconfig","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/configmaps/controller-manager-kubeconfig/kubeconfig,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/configmaps/controller-manager-kubeconfig/kubeconfig\n  If properly configured, the output should indicate the following group-owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-controller-manager-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-node-worker-file-groupowner-controller-manager-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692801","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-controller-manager-kubeconfig","uid":"d3d93c56-87fb-450e-8181-a6e92d1ca405"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Controller\nManager service. The aforementioned service is only running on\nthe nodes labeled \"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Etcd Database Directory\netcd is a highly-available key-value store used by Kubernetes deployments for\npersistent storage of all of its REST API objects. This data directory should\nbe protected from any unauthorized reads or writes.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_etcd_data_dir","instructions":"To check the group ownership of /var/lib/etcd/member/,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/lib/etcd/member/\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-etcd-data-dir"},"creationTimestamp":"2021-06-03T17:09:25Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:25Z"}],"name":"ocp4-cis-node-worker-file-groupowner-etcd-data-dir","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692886","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-etcd-data-dir","uid":"68448b1e-b494-4b27-b766-d96e8284866f"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Etcd Write-Ahead-Log Files\netcd is a highly-available key-value store used by Kubernetes deployments for\npersistent storage of all of its REST API objects. This data directory should\nbe protected from any unauthorized reads or writes.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_etcd_data_files","instructions":"To check the group ownership of /var/lib/etcd/member/wal/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/lib/etcd/member/wal/*\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-etcd-data-files"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-node-worker-file-groupowner-etcd-data-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692631","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-etcd-data-files","uid":"84d64281-7185-48a3-9fcf-293716cfc99a"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The etcd Member Pod Specification File\nThe etcd pod specification file controls various parameters that\nset the behavior of the etcd service in the master node. etcd is a\nhighly-available key-value store which Kubernetes uses for persistent\nstorage of all of its REST API object. You should restrict its file\npermissions to maintain the integrity of the file. The file should be\nwritable by only the administrators on the system.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_etcd_member","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/etcd-pod-*/etcd-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/static-pod-resources/etcd-pod-*/etcd-pod.yaml\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-etcd-member"},"creationTimestamp":"2021-06-03T17:09:25Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:25Z"}],"name":"ocp4-cis-node-worker-file-groupowner-etcd-member","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692884","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-etcd-member","uid":"ebbb0ed7-00d7-4dda-881f-3b2b154ed8d7"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Etcd PKI Certificate Files\nOpenShift makes use of a number of certificates as part of its operation.\nYou should verify the ownership of the directory containing the PKI\ninformation and all files in that directory to maintain their integrity.\nThe directory and files should be owned by the system administrator.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_etcd_pki_cert_files","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/*/*/*/*.crt,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/*/*/*/*.crt\n  If properly configured, the output should indicate the following group-owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-etcd-pki-cert-files"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-node-worker-file-groupowner-etcd-pki-cert-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692661","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-etcd-pki-cert-files","uid":"c18a2915-461a-4834-b326-17ad4fad948d"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The OpenShift SDN Container Network Interface Plugin IP Address Allocations\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_ip_allocations","instructions":"To check the group ownership of /var/lib/cni/networks/openshift-sdn/.*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/lib/cni/networks/openshift-sdn/.*\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-ip-allocations"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-node-worker-file-groupowner-ip-allocations","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692649","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-ip-allocations","uid":"bca38c9f-f179-458f-b8be-9659d737ab2b"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Kubernetes API Server Pod Specification File\nThe Kubernetes specification file contains information about the configuration of the\nKubernetes API Server that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_kube_apiserver","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/kube-apiserver-pod-*/kube-apiserver-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/static-pod-resources/kube-apiserver-pod-*/kube-apiserver-pod.yaml\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-kube-apiserver"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-node-worker-file-groupowner-kube-apiserver","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692824","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-kube-apiserver","uid":"1e85e5cf-9f2c-467c-a50f-6ca095fec097"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes API Server service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Kubernetes Controller Manager Pod Specification File\nThe Kubernetes specification file contains information about the configuration of the\nKubernetes Controller Manager Server that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_kube_controller_manager","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/kube-controller-manager-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/kube-controller-manager-pod.yaml\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-kube-controller-manager"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-node-worker-file-groupowner-kube-controller-manager","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692737","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-kube-controller-manager","uid":"1d2b634a-da5a-484f-9473-f57b3419129f"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Controller Manager service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Kubernetes Scheduler Pod Specification File\nThe Kubernetes Specification file contains information about the configuration of the\nKubernetes scheduler that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_kube_scheduler","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/kube-scheduler-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/kube-scheduler-pod.yaml\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-kube-scheduler"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-node-worker-file-groupowner-kube-scheduler","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692743","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-kube-scheduler","uid":"998b806a-34f5-4c04-8bf9-8832aa823f37"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Scheduler service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Kubelet Configuration File\nThe kubelet configuration file contains information about the configuration of the\nOpenShift node that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_kubelet_conf","instructions":"To check the group ownership of /etc/kubernetes/kubelet.conf,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/kubelet.conf\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-kubelet-conf"},"creationTimestamp":"2021-06-03T17:09:24Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:24Z"}],"name":"ocp4-cis-node-worker-file-groupowner-kubelet-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692861","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-kubelet-conf","uid":"542f6e35-2958-4ffc-9553-44ef3e786594"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The OpenShift Admin Kubeconfig Files\nThere are various kubeconfig files that can be used by the administrator,\ndefining various settings for the administration of the cluster. These files\ncontain credentials that can be used to control the cluster and are needed\nfor disaster recovery and each kubeconfig points to a different endpoint in\nthe cluster. You should restrict its file permissions to maintain the\nintegrity of the kubeconfig file as an attacker who gains access to these\nfiles can take over the cluster.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_master_admin_kubeconfigs","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/kube-apiserver-certs/secrets/node-kubeconfigs/*.kubeconfig,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/kube-apiserver-certs/secrets/node-kubeconfigs/*.kubeconfig\n  If properly configured, the output should indicate the following group-owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-master-admin-kubeconfigs"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-node-worker-file-groupowner-master-admin-kubeconfigs","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692759","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-master-admin-kubeconfigs","uid":"3a008f44-3d83-4426-b73c-f43a85d83be6"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes API server service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The OpenShift Multus Container Network Interface Plugin Files\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_multus_conf","instructions":"To check the group ownership of /var/run/multus/cni/net.d/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/run/multus/cni/net.d/*\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-multus-conf"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-node-worker-file-groupowner-multus-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692694","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-multus-conf","uid":"43ce67d1-96eb-4dcd-8597-2cffc3409a3e"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The OpenShift PKI Certificate Files\nOpenShift makes use of a number of certificates as part of its operation.\nYou should verify the ownership of the directory containing the PKI\ninformation and all files in that directory to maintain their integrity.\nThe directory and files should be owned by the system administrator.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_openshift_pki_cert_files","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/.*/.*/.*/tls.crt,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/.*/.*/.*/tls.crt\n  If properly configured, the output should indicate the following group-owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-openshift-pki-cert-files"},"creationTimestamp":"2021-06-03T17:09:24Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:24Z"}],"name":"ocp4-cis-node-worker-file-groupowner-openshift-pki-cert-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692876","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-openshift-pki-cert-files","uid":"060133ff-a6e6-4c0b-93b6-fb9a0263dd0d"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Control Plane.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The OpenShift PKI Private Key Files\nOpenShift makes use of a number of certificates as part of its operation.\nYou should verify the ownership of the directory containing the PKI\ninformation and all files in that directory to maintain their integrity.\nThe directory and files should be owned by root:root.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_openshift_pki_key_files","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/*/*/*/*.key,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/*/*/*/*.key\n  If properly configured, the output should indicate the following group-owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-openshift-pki-key-files"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-node-worker-file-groupowner-openshift-pki-key-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692781","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-openshift-pki-key-files","uid":"4a446eec-440b-44fc-9644-7ffb2d9bd547"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Control Plane.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The OpenShift SDN CNI Server Config\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_openshift_sdn_cniserver_config","instructions":"To check the group ownership of /var/run/openshift-sdn/cniserver/config.json,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/run/openshift-sdn/cniserver/config.json\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-openshift-sdn-cniserver-config"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-node-worker-file-groupowner-openshift-sdn-cniserver-config","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692847","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-openshift-sdn-cniserver-config","uid":"b85df39c-d3cc-4948-972b-4c24b8b8e7bb"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Open vSwitch Configuration Database\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_ovs_conf_db","instructions":"To check the group ownership of /etc/openvswitch/conf.db,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/openvswitch/conf.db\nIf properly configured, the output should indicate the following group-owner:\nhugetlbfs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-ovs-conf-db"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-node-worker-file-groupowner-ovs-conf-db","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692663","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-ovs-conf-db","uid":"6f9a178b-0622-4cbd-981d-003f0d1c6a29"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Open vSwitch Configuration Database Lock\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_ovs_conf_db_lock","instructions":"To check the group ownership of /etc/openvswitch/.conf.db.~lock~,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/openvswitch/.conf.db.~lock~\nIf properly configured, the output should indicate the following group-owner:\nhugetlbfs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-ovs-conf-db-lock"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-node-worker-file-groupowner-ovs-conf-db-lock","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692761","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-ovs-conf-db-lock","uid":"1b7b0854-7f5c-4172-b2d8-6fb1de066ccd"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Open vSwitch Process ID File\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_ovs_pid","instructions":"To check the group ownership of /var/run/openvswitch/ovs-vswitchd.pid,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/run/openvswitch/ovs-vswitchd.pid\nIf properly configured, the output should indicate the following group-owner:\nopenvswitch","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-ovs-pid"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-node-worker-file-groupowner-ovs-pid","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692634","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-ovs-pid","uid":"df71df9d-03cc-43c2-8485-f9f415d516cf"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Open vSwitch Persistent System ID\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_ovs_sys_id_conf","instructions":"To check the group ownership of /etc/openvswitch/system-id.conf,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/openvswitch/system-id.conf\nIf properly configured, the output should indicate the following group-owner:\nhugetlbfs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-ovs-sys-id-conf"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-node-worker-file-groupowner-ovs-sys-id-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692632","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-ovs-sys-id-conf","uid":"10c7fb29-5d9e-47ce-b348-b5ce0fda54d2"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Open vSwitch Daemon PID File\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_ovs_vswitchd_pid","instructions":"To check the group ownership of /run/openvswitch/ovs-vswitchd.pid,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /run/openvswitch/ovs-vswitchd.pid\nIf properly configured, the output should indicate the following group-owner:\nopenvswitch","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-ovs-vswitchd-pid"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-node-worker-file-groupowner-ovs-vswitchd-pid","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692679","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-ovs-vswitchd-pid","uid":"60fb56e0-776d-416e-b860-7e9195e7b39c"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Open vSwitch Database Server PID\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_ovsdb_server_pid","instructions":"To check the group ownership of /run/openvswitch/ovsdb-server.pid,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /run/openvswitch/ovsdb-server.pid\nIf properly configured, the output should indicate the following group-owner:\nopenvswitch","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-ovsdb-server-pid"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-node-worker-file-groupowner-ovsdb-server-pid","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692665","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-ovsdb-server-pid","uid":"d151ed97-a214-4954-9596-25c08aa30e43"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Kubernetes Scheduler Kubeconfig File\nThe kubeconfig for the Scheduler contains paramters for the scheduler\nto access the Kube API.\nYou should set its file ownership to maintain the integrity of the file.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_scheduler_kubeconfig","instructions":"To check the group ownership of /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/configmaps/scheduler-kubeconfig/kubeconfig,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/configmaps/scheduler-kubeconfig/kubeconfig\n  If properly configured, the output should indicate the following group-owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-scheduler-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-node-worker-file-groupowner-scheduler-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692696","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-scheduler-kubeconfig","uid":"7f0106bd-7d99-47a3-b5b5-e821a0be9fb6"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Scheduler service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns the Worker Certificate Authority File\nThe worker certificate authority file contains the certificate authority\ncertificate for an OpenShift node that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_worker_ca","instructions":"To check the group ownership of /etc/kubernetes/kubelet-ca.crt,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/kubelet-ca.crt\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-worker-ca"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-node-worker-file-groupowner-worker-ca","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692716","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-worker-ca","uid":"5691c924-1c55-4c7d-b4fd-7cc2d4e6701b"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The Worker Kubeconfig File\nThe worker kubeconfig file contains information about the administrative configuration of the\nOpenShift cluster that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_worker_kubeconfig","instructions":"To check the group ownership of /var/lib/kubelet/kubeconfig,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/lib/kubelet/kubeconfig\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-worker-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-node-worker-file-groupowner-worker-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692674","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-worker-kubeconfig","uid":"106a0569-ab73-41a8-af44-78f0bb898039"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Group Who Owns The OpenShift Node Service File\nfile contains information about the configuration of the\nOpenShift node service that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_groupowner_worker_service","instructions":"To check the group ownership of /etc/systemd/system/kubelet.service,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/systemd/system/kubelet.service\nIf properly configured, the output should indicate the following group-owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-groupowner-worker-service"},"creationTimestamp":"2021-06-03T17:09:24Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:24Z"}],"name":"ocp4-cis-node-worker-file-groupowner-worker-service","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692864","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-groupowner-worker-service","uid":"e5aeb2f8-9fd4-4ba1-aac9-cd9411084282"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The OpenShift Container Network Interface Files\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_cni_conf","instructions":"To check the ownership of /etc/cni/net.d/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/cni/net.d/*\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-cni-conf"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-node-worker-file-owner-cni-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692818","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-cni-conf","uid":"8e6b9e85-0b06-416d-94c5-64a31b2bd166"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The OpenShift Controller Manager Kubeconfig File\nThe Controller Manager's kubeconfig contains information about how the\ncomponent will access the API server. You should set its file ownership to\nmaintain the integrity of the file.","id":"xccdf_org.ssgproject.content_rule_file_owner_controller_manager_kubeconfig","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/configmaps/controller-manager-kubeconfig/kubeconfig,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/configmaps/controller-manager-kubeconfig/kubeconfig\n  If properly configured, the output should indicate the following owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-controller-manager-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-node-worker-file-owner-controller-manager-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692771","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-controller-manager-kubeconfig","uid":"5574a8a9-e2ef-449a-bf53-99d283eaff11"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Controller Manager service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Etcd Database Directory\netcd is a highly-available key-value store used by Kubernetes deployments for\npersistent storage of all of its REST API objects. This data directory should\nbe protected from any unauthorized reads or writes.","id":"xccdf_org.ssgproject.content_rule_file_owner_etcd_data_dir","instructions":"To check the ownership of /var/lib/etcd/member/,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/lib/etcd/member/\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-etcd-data-dir"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-node-worker-file-owner-etcd-data-dir","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692714","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-etcd-data-dir","uid":"a14be16e-afb9-4c9b-989d-20cc64937602"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Etcd Write-Ahead-Log Files\netcd is a highly-available key-value store used by Kubernetes deployments for\npersistent storage of all of its REST API objects. This data directory should\nbe protected from any unauthorized reads or writes.","id":"xccdf_org.ssgproject.content_rule_file_owner_etcd_data_files","instructions":"To check the ownership of /var/lib/etcd/member/wal/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/lib/etcd/member/wal/*\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-etcd-data-files"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-node-worker-file-owner-etcd-data-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692637","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-etcd-data-files","uid":"be572200-fa6e-4695-bc37-b9675512a208"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Etcd Member Pod Specification File\nThe etcd pod specification file controls various parameters that\nset the behavior of the etcd service in the master node. etcd is a\nhighly-available key-value store which Kubernetes uses for persistent\nstorage of all of its REST API object. You should restrict its file\npermissions to maintain the integrity of the file. The file should be\nwritable by only the administrators on the system.","id":"xccdf_org.ssgproject.content_rule_file_owner_etcd_member","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/etcd-pod-*/etcd-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/static-pod-resources/etcd-pod-*/etcd-pod.yaml\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-etcd-member"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-node-worker-file-owner-etcd-member","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692653","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-etcd-member","uid":"e8965af9-68ed-476a-a903-18d6f6a46851"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Etcd PKI Certificate Files\nOpenShift makes use of a number of certificates as part of its operation.\nYou should verify the ownership of the directory containing the PKI\ninformation and all files in that directory to maintain their integrity.\nThe directory and files should be owned by the system administrator.","id":"xccdf_org.ssgproject.content_rule_file_owner_etcd_pki_cert_files","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/*/*/*/*.crt,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/*/*/*/*.crt\n  If properly configured, the output should indicate the following owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-etcd-pki-cert-files"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-node-worker-file-owner-etcd-pki-cert-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692753","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-etcd-pki-cert-files","uid":"49115b3c-93bc-48f8-bbe5-186837648789"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The OpenShift SDN Container Network Interface Plugin IP Address Allocations\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_ip_allocations","instructions":"To check the ownership of /var/lib/cni/networks/openshift-sdn/.*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/lib/cni/networks/openshift-sdn/.*\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-ip-allocations"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-node-worker-file-owner-ip-allocations","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692804","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-ip-allocations","uid":"a42ddba2-9577-4997-8a95-2b400fba5a71"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Kubernetes API Server Pod Specification File\nThe Kubernetes specification file contains information about the configuration of the\nKubernetes API Server that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_owner_kube_apiserver","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/kube-apiserver-pod-*/kube-apiserver-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/static-pod-resources/kube-apiserver-pod-*/kube-apiserver-pod.yaml\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-kube-apiserver"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-node-worker-file-owner-kube-apiserver","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692687","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-kube-apiserver","uid":"aca420a2-3870-4037-9e0c-a5d41df4dfb8"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes API Server service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Kubernetes Controller Manager Pod Specificiation File\nThe Kubernetes specification file contains information about the configuration of the\nKubernetes Controller Manager Server that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_owner_kube_controller_manager","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/kube-controller-manager-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/kube-controller-manager-pod.yaml\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-kube-controller-manager"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-node-worker-file-owner-kube-controller-manager","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692648","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-kube-controller-manager","uid":"b8d3e72c-fb4b-4816-9342-52eb532f9b06"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Controller Manager service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Kubernetes Scheduler Pod Specification File\nThe Kubernetes specification file contains information about the configuration of the\nKubernetes scheduler that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_owner_kube_scheduler","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/kube-scheduler-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/kube-scheduler-pod.yaml\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-kube-scheduler"},"creationTimestamp":"2021-06-03T17:09:24Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:24Z"}],"name":"ocp4-cis-node-worker-file-owner-kube-scheduler","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692858","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-kube-scheduler","uid":"66569e90-cb43-4d99-9a51-d6a45348e2cf"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Scheduler service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Kubelet Configuration File\nThe kubelet configuration file contains information about the configuration of the\nOpenShift node that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_owner_kubelet_conf","instructions":"To check the ownership of /etc/kubernetes/kubelet.conf,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/kubelet.conf\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-kubelet-conf"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-node-worker-file-owner-kubelet-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692677","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-kubelet-conf","uid":"0a79d3ca-5ebf-4aa5-ab0d-0feb1dfdca47"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The OpenShift Admin Kubeconfig Files\nThere are various kubeconfig files that can be used by the administrator,\ndefining various settings for the administration of the cluster. These files\ncontain credentials that can be used to control the cluster and are needed\nfor disaster recovery and each kubeconfig points to a different endpoint in\nthe cluster. You should restrict its file permissions to maintain the\nintegrity of the kubeconfig file as an attacker who gains access to these\nfiles can take over the cluster.","id":"xccdf_org.ssgproject.content_rule_file_owner_master_admin_kubeconfigs","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/kube-apiserver-certs/secrets/node-kubeconfigs/*.kubeconfig,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/kube-apiserver-certs/secrets/node-kubeconfigs/*.kubeconfig\n  If properly configured, the output should indicate the following owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-master-admin-kubeconfigs"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-node-worker-file-owner-master-admin-kubeconfigs","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692639","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-master-admin-kubeconfigs","uid":"8a9ec85b-37f4-4fc5-be1a-317e96ebbdc9"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Control Plane.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The OpenShift Multus Container Network Interface Plugin Files\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_multus_conf","instructions":"To check the ownership of /var/run/multus/cni/net.d/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/run/multus/cni/net.d/*\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-multus-conf"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-node-worker-file-owner-multus-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692767","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-multus-conf","uid":"f719b5ce-a021-410c-b2e5-d30e12e6ae88"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The OpenShift PKI Certificate Files\nOpenShift makes use of a number of certificates as part of its operation.\nYou should verify the ownership of the directory containing the PKI\ninformation and all files in that directory to maintain their integrity.","id":"xccdf_org.ssgproject.content_rule_file_owner_openshift_pki_cert_files","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/*/*/*/tls.crt,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/*/*/*/tls.crt\n  If properly configured, the output should indicate the following owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-openshift-pki-cert-files"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-node-worker-file-owner-openshift-pki-cert-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692739","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-openshift-pki-cert-files","uid":"eb81cb23-321f-4798-8205-963e670d03d1"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Control Plane.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The OpenShift PKI Private Key Files\nOpenShift makes use of a number of certificates as part of its operation.\nYou should verify the ownership of the directory containing the PKI\ninformation and all files in that directory to maintain their integrity.\nThe directory and files should be owned by root:root.","id":"xccdf_org.ssgproject.content_rule_file_owner_openshift_pki_key_files","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/*/*/*/*.key,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/*/*/*/*.key\n  If properly configured, the output should indicate the following owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-openshift-pki-key-files"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-node-worker-file-owner-openshift-pki-key-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692708","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-openshift-pki-key-files","uid":"6828e117-f8bc-4fa9-bf4e-0293bcab3407"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Control Plane.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The OpenShift SDN CNI Server Config\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_openshift_sdn_cniserver_config","instructions":"To check the ownership of /var/run/openshift-sdn/cniserver/config.json,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/run/openshift-sdn/cniserver/config.json\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-openshift-sdn-cniserver-config"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-node-worker-file-owner-openshift-sdn-cniserver-config","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692786","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-openshift-sdn-cniserver-config","uid":"34a1514d-8fc3-4da3-832a-bcc71a33028c"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Open vSwitch Configuration Database\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_ovs_conf_db","instructions":"To check the ownership of /etc/openvswitch/conf.db,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/openvswitch/conf.db\nIf properly configured, the output should indicate the following owner:\nopenvswitch","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-ovs-conf-db"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-node-worker-file-owner-ovs-conf-db","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692741","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-ovs-conf-db","uid":"ef43beb4-e25c-4089-8b35-fa9bfce5f33e"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Open vSwitch Configuration Database Lock\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_ovs_conf_db_lock","instructions":"To check the ownership of /etc/openvswitch/.conf.db.~lock~,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/openvswitch/.conf.db.~lock~\nIf properly configured, the output should indicate the following owner:\nopenvswitch","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-ovs-conf-db-lock"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-node-worker-file-owner-ovs-conf-db-lock","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692659","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-ovs-conf-db-lock","uid":"170387e3-0534-434e-9153-3a54c1a8e483"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Open vSwitch Process ID File\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_ovs_pid","instructions":"To check the ownership of /var/run/openvswitch/ovs-vswitchd.pid,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/run/openvswitch/ovs-vswitchd.pid\nIf properly configured, the output should indicate the following owner:\nopenvswitch","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-ovs-pid"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-node-worker-file-owner-ovs-pid","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692712","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-ovs-pid","uid":"eddb1c10-1bb4-4652-b521-e1dab9958ba1"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Open vSwitch Persistent System ID\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_ovs_sys_id_conf","instructions":"To check the ownership of /etc/openvswitch/system-id.conf,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/openvswitch/system-id.conf\nIf properly configured, the output should indicate the following owner:\nopenvswitch","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-ovs-sys-id-conf"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-node-worker-file-owner-ovs-sys-id-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692788","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-ovs-sys-id-conf","uid":"465ab3ee-24d8-45df-80be-f3f84560aa48"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Open vSwitch Daemon PID File\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_ovs_vswitchd_pid","instructions":"To check the ownership of /run/openvswitch/ovs-vswitchd.pid,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /run/openvswitch/ovs-vswitchd.pid\nIf properly configured, the output should indicate the following owner:\nopenvswitch","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-ovs-vswitchd-pid"},"creationTimestamp":"2021-06-03T17:09:24Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:24Z"}],"name":"ocp4-cis-node-worker-file-owner-ovs-vswitchd-pid","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692877","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-ovs-vswitchd-pid","uid":"9924adfe-2a07-4f17-82f4-6a738a1d4712"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Open vSwitch Database Server PID\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_owner_ovsdb_server_pid","instructions":"To check the ownership of /run/openvswitch/ovsdb-server.pid,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /run/openvswitch/ovsdb-server.pid\nIf properly configured, the output should indicate the following owner:\nopenvswitch","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-ovsdb-server-pid"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-node-worker-file-owner-ovsdb-server-pid","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692635","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-ovsdb-server-pid","uid":"74759735-acf8-4a4c-9f14-45464bb03350"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Kubernetes Scheduler Kubeconfig File\nThe kubeconfig for the Scheduler contains paramters for the scheduler\nto access the Kube API.\nYou should set its file ownership to maintain the integrity of the file.","id":"xccdf_org.ssgproject.content_rule_file_owner_scheduler_kubeconfig","instructions":"To check the ownership of /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/configmaps/scheduler-kubeconfig/kubeconfig,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -lL /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/configmaps/scheduler-kubeconfig/kubeconfig\n  If properly configured, the output should indicate the following owner:\n  root","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-scheduler-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-node-worker-file-owner-scheduler-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692816","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-scheduler-kubeconfig","uid":"4669b0d0-a767-49bc-b83e-ecaf046a44b1"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Scheduler service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns the Worker Certificate Authority File\nThe worker certificate authority file contains the certificate authority\ncertificate for an OpenShift node that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_owner_worker_ca","instructions":"To check the ownership of /etc/kubernetes/kubelet-ca.crt,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/kubernetes/kubelet-ca.crt\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-worker-ca"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-node-worker-file-owner-worker-ca","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692670","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-worker-ca","uid":"303170cb-e4d1-4d43-aa46-1a996c9c9429"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The Worker Kubeconfig File\nThe worker kubeconfig file contains information about the administrative configuration of the\nOpenShift cluster that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_owner_worker_kubeconfig","instructions":"To check the ownership of /var/lib/kubelet/kubeconfig,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /var/lib/kubelet/kubeconfig\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-worker-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-node-worker-file-owner-worker-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692773","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-worker-kubeconfig","uid":"3d27b469-82f6-4c63-876f-bef28abed86b"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify User Who Owns The OpenShift Node Service File\nfile contains information about the configuration of the\nOpenShift node service that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_owner_worker_service","instructions":"To check the ownership of /etc/systemd/system/kubelet.service,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -lL /etc/systemd/system/kubelet.service\nIf properly configured, the output should indicate the following owner:\nroot","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-owner-worker-service"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-node-worker-file-owner-worker-service","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692667","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-owner-worker-service","uid":"997efadc-9a81-4395-a114-5d85c4053536"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the OpenShift Container Network Interface Files\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_permissions_cni_conf","instructions":"To check the permissions of /etc/cni/net.d/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/cni/net.d/*\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-cni-conf"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-node-worker-file-permissions-cni-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692641","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-cni-conf","uid":"a74537dc-95e7-4082-b7f9-58d3c288a3da"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the OpenShift Controller Manager Kubeconfig File\nThe Controller Manager's kubeconfig contains information about how the\ncomponent will access the API server. You should restrict its file\npermissions to maintain the integrity of the file. The file should be\nwritable by only the administrators on the system.","id":"xccdf_org.ssgproject.content_rule_file_permissions_controller_manager_kubeconfig","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/configmaps/controller-manager-kubeconfig/kubeconfig,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -l /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/configmaps/controller-manager-kubeconfig/kubeconfig\n  If properly configured, the output should indicate the following permissions:\n  -rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-controller-manager-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-node-worker-file-permissions-controller-manager-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692685","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-controller-manager-kubeconfig","uid":"e65aba6b-9117-49cd-8a2c-e7571cf179f6"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Controller Manager service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Etcd Database Directory\netcd is a highly-available key-value store used by Kubernetes deployments for persistent\nstorage of all of its REST API objects. This data directory should be protected from any\nunauthorized reads or writes. It should not be readable or writable by any group members\nor the world.","id":"xccdf_org.ssgproject.content_rule_file_permissions_etcd_data_dir","instructions":"To check the permissions of /var/lib/etcd,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /var/lib/etcd\nIf properly configured, the output should indicate the following permissions:\ndrwx------","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-etcd-data-dir"},"creationTimestamp":"2021-06-03T17:09:24Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:24Z"}],"name":"ocp4-cis-node-worker-file-permissions-etcd-data-dir","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692870","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-etcd-data-dir","uid":"9f61331b-b962-4516-8a71-22e6d7af8271"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Etcd Write-Ahead-Log Files\netcd is a highly-available key-value store used by Kubernetes deployments for persistent\nstorage of all of its REST API objects. This data directory should be protected from any\nunauthorized reads or writes. It should not be readable or writable by any group members\nor the world.","id":"xccdf_org.ssgproject.content_rule_file_permissions_etcd_data_files","instructions":"To check the permissions of /var/lib/etcd/member/wal/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /var/lib/etcd/member/wal/*\nIf properly configured, the output should indicate the following permissions:\n-rw-------","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-etcd-data-files"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-node-worker-file-permissions-etcd-data-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692765","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-etcd-data-files","uid":"9a630492-4647-4a04-8e2b-225787a181a5"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Etcd Member Pod Specification File\nThe etcd pod specification file controls various parameters that\nset the behavior of the etcd service in the master node. etcd is a\nhighly-available key-value store which Kubernetes uses for persistent\nstorage of all of its REST API object. You should restrict its file\npermissions to maintain the integrity of the file. The file should be\nwritable by only the administrators on the system.","id":"xccdf_org.ssgproject.content_rule_file_permissions_etcd_member","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/etcd-pod-*/etcd-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/kubernetes/static-pod-resources/etcd-pod-*/etcd-pod.yaml\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-etcd-member"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-node-worker-file-permissions-etcd-member","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692646","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-etcd-member","uid":"afcbf035-0aca-4b8f-b664-2b68528a76de"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Etcd PKI Certificate Files\nor more restrictive to protect their integrity.","id":"xccdf_org.ssgproject.content_rule_file_permissions_etcd_pki_cert_files","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/etcd-*/secrets/*/*.crt,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -l /etc/kubernetes/static-pod-resources/etcd-*/secrets/*/*.crt\n  If properly configured, the output should indicate the following permissions:\n  -rw-------","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-etcd-pki-cert-files"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-node-worker-file-permissions-etcd-pki-cert-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692722","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-etcd-pki-cert-files","uid":"4b135fbd-0452-4c5a-b57f-b06418b2114d"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Etcd service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the OpenShift SDN Container Network Interface Plugin IP Address Allocations\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_permissions_ip_allocations","instructions":"To check the permissions of /var/lib/cni/networks/openshift-sdn/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /var/lib/cni/networks/openshift-sdn/*\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-ip-allocations"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-node-worker-file-permissions-ip-allocations","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692820","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-ip-allocations","uid":"85f195f1-5c4e-40b4-9df3-42691f2194bd"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Kubernetes API Server Pod Specification File\nIf the Kubernetes specification file is writable by a group-owner or the\nworld the risk of its compromise is increased. The file contains the configuration of\nthe Kubernetes API server that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_permissions_kube_apiserver","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/kube-apiserver-pod-*/kube-apiserver-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/kubernetes/static-pod-resources/kube-apiserver-pod-*/kube-apiserver-pod.yaml\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-kube-apiserver"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-node-worker-file-permissions-kube-apiserver","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692783","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-kube-apiserver","uid":"1bc77eba-71fb-4d50-be16-0ea39c5a4a31"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes API Server service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Kubernetes Controller Manager Pod Specificiation File\nIf the Kubernetes specification file is writable by a group-owner or the\nworld the risk of its compromise is increased. The file contains the configuration of\nan Kubernetes Controller Manager server that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_permissions_kube_controller_manager","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/kube-controller-manager-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-*/kube-controller-manager-pod.yaml\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-kube-controller-manager"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-node-worker-file-permissions-kube-controller-manager","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692778","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-kube-controller-manager","uid":"4e9f66fd-3b33-43d4-8e94-0a302f8fefc1"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Controller Manager service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on The Kubelet Configuration File\nIf the kubelet configuration file is writable by a group-owner or the\nworld the risk of its compromise is increased. The file contains the configuration of\nan OpenShift node that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_permissions_kubelet_conf","instructions":"To check the permissions of /etc/kubernetes/kubelet.conf,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/kubernetes/kubelet.conf\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-kubelet-conf"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-node-worker-file-permissions-kubelet-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692757","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-kubelet-conf","uid":"e691053c-7ecc-4619-9abf-8dfad2739d78"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the OpenShift Admin Kubeconfig Files\nThere are various kubeconfig files that can be used by the administrator,\ndefining various settings for the administration of the cluster. These files\ncontain credentials that can be used to control the cluster and are needed\nfor disaster recovery and each kubeconfig points to a different endpoint in\nthe cluster. You should restrict its file permissions to maintain the\nintegrity of the kubeconfig file as an attacker who gains access to these\nfiles can take over the cluster.","id":"xccdf_org.ssgproject.content_rule_file_permissions_master_admin_kubeconfigs","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/kube-apiserver-certs/secrets/node-kubeconfigs/*.kubeconfig,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -l /etc/kubernetes/static-pod-resources/kube-apiserver-certs/secrets/node-kubeconfigs/*.kubeconfig\n  If properly configured, the output should indicate the following permissions:\n  -rw-------","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-master-admin-kubeconfigs"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-node-worker-file-permissions-master-admin-kubeconfigs","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692690","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-master-admin-kubeconfigs","uid":"2256b999-7d57-489f-b7fe-2b61b14b17a8"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Control Plane.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the OpenShift Multus Container Network Interface Plugin Files\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_permissions_multus_conf","instructions":"To check the permissions of /var/run/multus/cni/net.d/*,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /var/run/multus/cni/net.d/*\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-multus-conf"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-node-worker-file-permissions-multus-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692851","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-multus-conf","uid":"6fb82c40-8540-4a1f-9727-0237c7a3fcdc"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the OpenShift PKI Certificate Files\nor more restrictive to protect their integrity.","id":"xccdf_org.ssgproject.content_rule_file_permissions_openshift_pki_cert_files","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/kube-*/secrets/*/tls.crt,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -l /etc/kubernetes/static-pod-resources/kube-*/secrets/*/tls.crt\n  If properly configured, the output should indicate the following permissions:\n  -rw-------","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-openshift-pki-cert-files"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-node-worker-file-permissions-openshift-pki-cert-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692701","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-openshift-pki-cert-files","uid":"6db45142-8250-4d3f-8faf-4395acda3884"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Control Plane.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the OpenShift PKI Private Key Files\nto protect their integrity and confidentiality.","id":"xccdf_org.ssgproject.content_rule_file_permissions_openshift_pki_key_files","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/*/*/*/*.key,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -l /etc/kubernetes/static-pod-resources/*/*/*/*.key\n  If properly configured, the output should indicate the following permissions:\n  -rw-------","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-openshift-pki-key-files"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-node-worker-file-permissions-openshift-pki-key-files","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692651","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-openshift-pki-key-files","uid":"cee54770-ef6b-4221-9ce8-bc02c77b4dd2"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Control Plane.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Open vSwitch Configuration Database\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_permissions_ovs_conf_db","instructions":"To check the permissions of /etc/openvswitch/conf.db,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/openvswitch/conf.db\nIf properly configured, the output should indicate the following permissions:\n-rw-r-----","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-ovs-conf-db"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-node-worker-file-permissions-ovs-conf-db","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692718","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-ovs-conf-db","uid":"f129a933-f6be-45f6-a58e-a6db76647055"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Open vSwitch Configuration Database Lock\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_permissions_ovs_conf_db_lock","instructions":"To check the permissions of /etc/openvswitch/.conf.db.~lock~,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/openvswitch/.conf.db.~lock~\nIf properly configured, the output should indicate the following permissions:\n-rw-------","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-ovs-conf-db-lock"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-node-worker-file-permissions-ovs-conf-db-lock","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692657","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-ovs-conf-db-lock","uid":"0af2493a-b69b-4999-98fc-261b8a9c0afd"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Open vSwitch Process ID File\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_permissions_ovs_pid","instructions":"To check the permissions of /var/run/openvswitch/ovs-vswitchd.pid,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /var/run/openvswitch/ovs-vswitchd.pid\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-ovs-pid"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-node-worker-file-permissions-ovs-pid","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692633","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-ovs-pid","uid":"baa718eb-9a88-4f7f-aa8c-6cdaa1935383"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Open vSwitch Persistent System ID\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_permissions_ovs_sys_id_conf","instructions":"To check the permissions of /etc/openvswitch/system-id.conf,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/openvswitch/system-id.conf\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-ovs-sys-id-conf"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-node-worker-file-permissions-ovs-sys-id-conf","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692698","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-ovs-sys-id-conf","uid":"0a09343d-e9a6-4861-9694-325206a220d6"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Open vSwitch Daemon PID File\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_permissions_ovs_vswitchd_pid","instructions":"To check the permissions of /run/openvswitch/ovs-vswitchd.pid,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /run/openvswitch/ovs-vswitchd.pid\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-ovs-vswitchd-pid"},"creationTimestamp":"2021-06-03T17:09:24Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:24Z"}],"name":"ocp4-cis-node-worker-file-permissions-ovs-vswitchd-pid","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692872","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-ovs-vswitchd-pid","uid":"371d6a32-0e4b-4085-98d1-32780906f741"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Open vSwitch Database Server PID\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_permissions_ovsdb_server_pid","instructions":"To check the permissions of /run/openvswitch/ovsdb-server.pid,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /run/openvswitch/ovsdb-server.pid\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-ovsdb-server-pid"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-node-worker-file-permissions-ovsdb-server-pid","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692799","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-ovsdb-server-pid","uid":"71505b13-5ee6-4e6f-a249-394af474bfdb"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Kubernetes Scheduler Pod Specification File\nIf the Kubernetes specification file is writable by a group-owner or the\nworld the risk of its compromise is increased. The file contains the configuration of\nan Kubernetes Scheduler service that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_permissions_scheduler","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/kube-scheduler-pod.yaml,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/kube-scheduler-pod.yaml\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-scheduler"},"creationTimestamp":"2021-06-03T17:09:25Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:25Z"}],"name":"ocp4-cis-node-worker-file-permissions-scheduler","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692885","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-scheduler","uid":"8a40b624-4200-494e-8409-6f660438e673"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Scheduler service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Kubernetes Scheduler Kubeconfig File\nThe kubeconfig for the Scheduler contains paramters for the scheduler\nto access the Kube API. You should restrict its file permissions to maintain\nthe integrity of the file. The file should be writable by only the\nadministrators on the system.","id":"xccdf_org.ssgproject.content_rule_file_permissions_scheduler_kubeconfig","instructions":"To check the permissions of /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/configmaps/scheduler-kubeconfig/kubeconfig,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -l /etc/kubernetes/static-pod-resources/kube-scheduler-pod-*/configmaps/scheduler-kubeconfig/kubeconfig\n  If properly configured, the output should indicate the following permissions:\n  -rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-scheduler-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"NOT-APPLICABLE","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-node-worker-file-permissions-scheduler-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692682","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-scheduler-kubeconfig","uid":"03fff236-e682-4275-ba84-1aafd87fc5e3"},"severity":"medium","status":"NOT-APPLICABLE","warnings":["This rule is only applicable for nodes that run the Kubernetes Scheduler service.\nThe aforementioned service is only running on the nodes labeled\n\"master\" by default."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Worker Certificate Authority File\nIf the worker certificate authority file is writable by a group-owner or the\nworld the risk of its compromise is increased. The file contains the certificate authority\ncertificate for an OpenShift node that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_permissions_worker_ca","instructions":"To check the permissions of /etc/kubernetes/kubelet-ca.crt,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /etc/kubernetes/kubelet-ca.crt\nIf properly configured, the output should indicate the following permissions:\n-rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-worker-ca"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-node-worker-file-permissions-worker-ca","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692672","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-worker-ca","uid":"94c5ba0b-f6d2-4b52-98c4-eb8c05779457"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the Worker Kubeconfig File\nIf the worker kubeconfig file is writable by a group-owner or the\nworld the risk of its compromise is increased. The file contains the administration configuration of the\nOpenShift cluster that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_permissions_worker_kubeconfig","instructions":"To check the permissions of /var/lib/kubelet/kubeconfig,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /var/lib/kubelet/kubeconfig\nIf properly configured, the output should indicate the following permissions:\n-rw-------","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-worker-kubeconfig"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-node-worker-file-permissions-worker-kubeconfig","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692755","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-worker-kubeconfig","uid":"864730da-dfda-41bb-80c6-f5c17152f007"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the OpenShift Node Service File\nfile is writable by a group-owner or the\nworld the risk of its compromise is increased. The file contains the service configuration of the\nOpenShift node service that is configured on the system. Protection of this file is\ncritical for OpenShift security.","id":"xccdf_org.ssgproject.content_rule_file_permissions_worker_service","instructions":"To check the permissions of /etc/systemd/system/kubelet.service,\n  you'll need to log into a node in the cluster.\n  As a user with administrator privileges, log into a node in the relevant pool:\n  \n  $ oc debug node/$NODE_NAME\n  \n  At the sh-4.4# prompt, run:\n  \n  # chroot /host\n  \n\n  Then,run the command:\n  $ ls -l /etc/systemd/system/kubelet.service\n  If properly configured, the output should indicate the following permissions:\n  -rw-r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-permissions-worker-service"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-node-worker-file-permissions-worker-service","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692640","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-permissions-worker-service","uid":"06ad4f5b-b668-4e41-acc8-e7d1356d590b"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Verify Permissions on the OpenShift SDN CNI Server Config\nCNI (Container Network Interface) files consist of a specification and libraries for\nwriting plugins to configure network interfaces in Linux containers, along with a number\nof supported plugins. Allowing writeable access to the files could allow an attacker to modify\nthe networking configuration potentially adding a rogue network connection.","id":"xccdf_org.ssgproject.content_rule_file_perms_openshift_sdn_cniserver_config","instructions":"To check the permissions of /var/run/openshift-sdn/cniserver/config.json,\nyou'll need to log into a node in the cluster.\nAs a user with administrator privileges, log into a node in the relevant pool:\n\n$ oc debug node/$NODE_NAME\n\nAt the sh-4.4# prompt, run:\n\n# chroot /host\n\n\nThen,run the command:\n$ ls -l /var/run/openshift-sdn/cniserver/config.json\nIf properly configured, the output should indicate the following permissions:\n-r--r--r--","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"file-perms-openshift-sdn-cniserver-config"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-node-worker-file-perms-openshift-sdn-cniserver-config","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692636","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-file-perms-openshift-sdn-cniserver-config","uid":"3979766c-e780-440e-b8f7-17cbfc25c1c3"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Disable Anonymous Authentication to the Kubelet\nWhen enabled, requests that are not rejected by other configured\nauthentication methods are treated as anonymous requests. These\nrequests are then served by the Kubelet server. OpenShift Operators should\nrely on authentication to authorize access and disallow anonymous\nrequests.","id":"xccdf_org.ssgproject.content_rule_kubelet_anonymous_auth","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep -A1 anonymous /etc/kubernetes/kubelet.conf\nThe output should return enabled: false.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-anonymous-auth"},"creationTimestamp":"2021-06-03T17:09:24Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:24Z"}],"name":"ocp4-cis-node-worker-kubelet-anonymous-auth","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692867","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-anonymous-auth","uid":"610dafb0-0fc4-4ce6-9b14-2c47f0e00f09"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure authorization is set to Webhook\nEnsuring that the authorization is configured correctly helps enforce that\nunauthenticated/unauthorized users have no access to OpenShift nodes.","id":"xccdf_org.ssgproject.content_rule_kubelet_authorization_mode","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep -A1 authorization /etc/kubernetes/kubelet.conf\nVerify that the output is not set to mode: AlwaysAllow, or missing\n(defaults to mode: Webhook).","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-authorization-mode"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-node-worker-kubelet-authorization-mode","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692814","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-authorization-mode","uid":"962355c1-2e11-48c2-a029-4eb18d3d2607"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"kubelet - Configure the Client CA Certificate\nNot having a CA certificate for the kubelet will subject the kubelet to possible\nman-in-the-middle attacks especially on unsafe or untrusted networks.\nCertificate validation for the kubelet allows the API server to validate\nthe kubelet's identity.","id":"xccdf_org.ssgproject.content_rule_kubelet_configure_client_ca","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep -A1 x509 /etc/kubernetes/kubelet.conf\nThe output should contain a configured certificate like /etc/kubernetes/kubelet-ca.crt.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-configure-client-ca"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-node-worker-kubelet-configure-client-ca","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692630","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-configure-client-ca","uid":"5907566d-9cb0-4aa5-a231-087cd0df900a"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Kubelet - Ensure Event Creation Is Configured\nIt is important to capture all events and not restrict event creation.\nEvents are an important source of security information and analytics that\nensure that your environment is consistently monitored using the event\ndata.","id":"xccdf_org.ssgproject.content_rule_kubelet_configure_event_creation","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep eventRecordQPS /etc/kubernetes/kubelet.conf\nThe output should return .","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-configure-event-creation"},"creationTimestamp":"2021-06-03T17:09:25Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{},"f:warnings":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:25Z"}],"name":"ocp4-cis-node-worker-kubelet-configure-event-creation","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692881","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-configure-event-creation","uid":"5fd2bbe5-8c87-4a5a-8a31-a904da1e005a"},"severity":"medium","status":"FAIL","warnings":["object."]},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure that the Kubelet only makes use of Strong Cryptographic Ciphers\nTLS ciphers have had a number of known vulnerabilities and weaknesses,\nwhich can reduce the protection provided by them. By default Kubernetes\nsupports a number of TLS ciphersuites including some that have security\nconcerns, weakening the protection provided.","id":"xccdf_org.ssgproject.content_rule_kubelet_configure_tls_cipher_suites","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep tlsCipherSuites /etc/kubernetes/kubelet.conf\nVerify that the set of ciphers contains only the following:\n\nTLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,\nTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,\nTLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,\nTLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-configure-tls-cipher-suites"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-node-worker-kubelet-configure-tls-cipher-suites","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692730","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-configure-tls-cipher-suites","uid":"8feb2374-086e-4c15-991d-3a5dfbd60326"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"kubelet - Disable Hostname Override\nAllowing hostnames to be overrided creates issues around resolving nodes\nin addition to TLS configuration, certificate validation, and log correlation\nand validation.","id":"xccdf_org.ssgproject.content_rule_kubelet_disable_hostname_override","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep hostname-override /etc/systemd/system/kubelet.service\nThe output should return no output.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-disable-hostname-override"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-node-worker-kubelet-disable-hostname-override","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692750","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-disable-hostname-override","uid":"153fb643-aa0e-4c47-bcfe-371bcab01f61"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"kubelet - Enable Certificate Rotation\nAllowing the kubelet to auto-update the certificates ensure that there is no downtime\nin certificate renewal as well as ensures confidentiality and integrity.","id":"xccdf_org.ssgproject.content_rule_kubelet_enable_cert_rotation","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep rotateCertificates /etc/kubernetes/kubelet.conf\nThe output should return true.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-enable-cert-rotation"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-node-worker-kubelet-enable-cert-rotation","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692644","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-enable-cert-rotation","uid":"b2d63812-00a0-4b67-8b1b-a3d0e2bf758a"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"kubelet - Enable Client Certificate Rotation\nAllowing the kubelet to auto-update the certificates ensure that there is no downtime\nin certificate renewal as well as ensures confidentiality and integrity.","id":"xccdf_org.ssgproject.content_rule_kubelet_enable_client_cert_rotation","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep RotateKubeletClientCertificate /etc/kubernetes/kubelet.conf\nThe output should return true.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-enable-client-cert-rotation"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-node-worker-kubelet-enable-client-cert-rotation","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692745","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-enable-client-cert-rotation","uid":"53184413-d13a-46ea-8ce0-155a5f5ac108"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"kubelet - Allow Automatic Firewall Configuration\nThe kubelet should automatically configure the firewall settings to allow access and\nnetworking traffic through. This ensures that when a pod or container is running that\nthe correct ports are configured as well as removing the ports when a pod or\ncontainer is no longer in existence.","id":"xccdf_org.ssgproject.content_rule_kubelet_enable_iptables_util_chains","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep makeIPTablesUtilChains /etc/kubernetes/kubelet.conf\nThe output should return true.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-enable-iptables-util-chains"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-node-worker-kubelet-enable-iptables-util-chains","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692812","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-enable-iptables-util-chains","uid":"dc20da0b-99d7-432c-bc50-6075f2abdec6"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"kubelet - Enable Protect Kernel Defaults\nKernel parameters are usually tuned and hardened by the system administrators\nbefore putting the systems into production. These parameters protect the\nkernel and the system. Your kubelet kernel defaults that rely on such\nparameters should be appropriately set to match the desired secured system\nstate. Ignoring this could potentially lead to running pods with undesired\nkernel behavior.","id":"xccdf_org.ssgproject.content_rule_kubelet_enable_protect_kernel_defaults","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep protectKernelDefaults /etc/kubernetes/kubelet.conf\nThe output should return true.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-enable-protect-kernel-defaults"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-node-worker-kubelet-enable-protect-kernel-defaults","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692655","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-enable-protect-kernel-defaults","uid":"453ad6c4-7782-4b8d-a426-9d7f8afac788"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"kubelet - Enable Server Certificate Rotation\nAllowing the kubelet to auto-update the certificates ensure that there is no downtime\nin certificate renewal as well as ensures confidentiality and integrity.","id":"xccdf_org.ssgproject.content_rule_kubelet_enable_server_cert_rotation","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep RotateKubeletServerCertificate /etc/kubernetes/kubelet.conf\nThe output should return true.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-enable-server-cert-rotation"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-node-worker-kubelet-enable-server-cert-rotation","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692735","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-enable-server-cert-rotation","uid":"fd4ac28f-9eac-4557-a921-5a91ffa41c35"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"kubelet - Do Not Disable Streaming Timeouts\nEnsuring connections have timeouts helps to protect against denial-of-service attacks as\nwell as disconnect inactive connections. In addition, setting connections timeouts helps\nto prevent from running out of ephemeral ports.","id":"xccdf_org.ssgproject.content_rule_kubelet_enable_streaming_connections","instructions":"Run the following command on the kubelet node(s):\n$ sudo grep streamingConnectionIdleTimeout /etc/kubernetes/kubelet.conf\nThe output should return .","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-enable-streaming-connections"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-node-worker-kubelet-enable-streaming-connections","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692642","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-enable-streaming-connections","uid":"37ce24c5-cb4d-46cc-bed7-7f9dc5663d65"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionHard: imagefs.available\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_hard_imagefs_available","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionHard.\"imagefs.available\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-hard-imagefs-available"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-node-worker-kubelet-eviction-thresholds-set-hard-imagefs-available","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692822","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-eviction-thresholds-set-hard-imagefs-available","uid":"de01eeb3-0b32-4e41-ae24-6c935f06bc84"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionHard: imagefs.inodesFree\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_hard_imagefs_inodesfree","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionHard.\"imagefs.inodesFree\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-hard-imagefs-inodesfree"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-node-worker-kubelet-eviction-thresholds-set-hard-imagefs-inodesfree","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692795","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-eviction-thresholds-set-hard-imagefs-inodesfree","uid":"825418ac-08e3-4add-b018-3b1ed3727387"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionHard: memory.available\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_hard_memory_available","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionHard.\"memory.available\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-hard-memory-available"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-node-worker-kubelet-eviction-thresholds-set-hard-memory-available","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692710","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-eviction-thresholds-set-hard-memory-available","uid":"3efb7956-6066-4da6-bbf0-ca1d140b3c8a"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionHard: nodefs.available\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_hard_nodefs_available","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionHard.\"nodefs.available\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-hard-nodefs-available"},"creationTimestamp":"2021-06-03T17:09:24Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:24Z"}],"name":"ocp4-cis-node-worker-kubelet-eviction-thresholds-set-hard-nodefs-available","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692879","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-eviction-thresholds-set-hard-nodefs-available","uid":"54117776-b9a6-43f2-8f24-0f54fe1b7923"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionHard: nodefs.inodesFree\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_hard_nodefs_inodesfree","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionHard.\"nodefs.inodesFree\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-hard-nodefs-inodesfree"},"creationTimestamp":"2021-06-03T17:09:25Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:25Z"}],"name":"ocp4-cis-node-worker-kubelet-eviction-thresholds-set-hard-nodefs-inodesfree","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692883","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-eviction-thresholds-set-hard-nodefs-inodesfree","uid":"7d3379fb-7e2d-454b-b9d2-5c65cc876aa2"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionSoft: imagefs.available\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_soft_imagefs_available","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionSoft.\"imagefs.available\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-soft-imagefs-available"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-node-worker-kubelet-eviction-thresholds-set-soft-imagefs-available","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692732","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-eviction-thresholds-set-soft-imagefs-available","uid":"f7502fd0-5945-455e-9cbf-f07a112fb710"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionSoft: imagefs.inodesFree\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_soft_imagefs_inodesfree","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionSoft.\"imagefs.inodesFree\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-soft-imagefs-inodesfree"},"creationTimestamp":"2021-06-03T17:09:21Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:21Z"}],"name":"ocp4-cis-node-worker-kubelet-eviction-thresholds-set-soft-imagefs-inodesfree","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692775","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-eviction-thresholds-set-soft-imagefs-inodesfree","uid":"a636a8b8-b522-4a8a-b8bf-8cbf2559fccb"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionSoft: memory.available\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_soft_memory_available","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionSoft.\"memory.available\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-soft-memory-available"},"creationTimestamp":"2021-06-03T17:09:17Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:17Z"}],"name":"ocp4-cis-node-worker-kubelet-eviction-thresholds-set-soft-memory-available","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692645","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-eviction-thresholds-set-soft-memory-available","uid":"d019a313-a93d-4879-ade9-7b045ca9390a"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionSoft: nodefs.available\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_soft_nodefs_available","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionSoft.\"nodefs.available\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-soft-nodefs-available"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-node-worker-kubelet-eviction-thresholds-set-soft-nodefs-available","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692797","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-eviction-thresholds-set-soft-nodefs-available","uid":"821a46fd-aa82-4177-a1e9-2c6178ad9e0c"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure Eviction threshold Settings Are Set - evictionSoft: nodefs.inodesFree\nGarbage collection is important to ensure sufficient resource availability\nand avoiding degraded performance and availability. In the worst case, the\nsystem might crash or just be unusable for a long period of time.\nBased on your system resources and tests, choose an appropriate threshold\nvalue to activate garbage collection.","id":"xccdf_org.ssgproject.content_rule_kubelet_eviction_thresholds_set_soft_nodefs_inodesfree","instructions":"Run the following command on the kubelet node(s):\n$ oc debug -q node/$NODE -- jq -r '.evictionSoft.\"nodefs.inodesFree\"' /host/etc/kubernetes/kubelet.conf\nand make sure it outputs","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"kubelet-eviction-thresholds-set-soft-nodefs-inodesfree"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"FAIL","compliance.openshift.io/scan-name":"ocp4-cis-node-worker","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc9a521e-cabd-4a78-a5e5-744610b284fd\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-node-worker-kubelet-eviction-thresholds-set-soft-nodefs-inodesfree","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis-node-worker","uid":"dc9a521e-cabd-4a78-a5e5-744610b284fd"}],"resourceVersion":"44692807","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-node-worker-kubelet-eviction-thresholds-set-soft-nodefs-inodesfree","uid":"446194e8-d44a-4ce4-ba6b-d13db8fd07ac"},"severity":"medium","status":"FAIL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure the OpenShift API Server Maximum Retained Audit Logs\nOpenShift automatically rotates the log files. Retaining old log files ensures\nOpenShift Operators will have sufficient log data available for carrying out\nany investigation or correlation. For example, if the audit log size is set to\n100 MB and the number of retained log files is set to 10, OpenShift Operators\nwould have approximately 1 GB of log data to use during analysis.","id":"xccdf_org.ssgproject.content_rule_ocp_api_server_audit_log_maxbackup","instructions":"Run the following command:\n$ oc get configmap config -n openshift-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq '.apiServerArguments[\"audit-log-maxbackup\"][0]'\nThe output should return a value of 10 or as appropriate.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"ocp-api-server-audit-log-maxbackup"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"low","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-ocp-api-server-audit-log-maxbackup","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692776","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-ocp-api-server-audit-log-maxbackup","uid":"0751a267-9aaa-4ece-9737-4ee6bacf5bd9"},"severity":"low","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure OpenShift API Server Maximum Audit Log Size\nOpenShift automatically rotates log files. Retaining old log files ensures that\nOpenShift Operators have sufficient log data available for carrying out any\ninvestigation or correlation. If you have set file size of 100 MB and the number of\nold log files to keep as 10, there would be approximately 1 GB of log data\navailable for use in analysis.","id":"xccdf_org.ssgproject.content_rule_ocp_api_server_audit_log_maxsize","instructions":"Run the following command:\n$ oc get configmap config -n openshift-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq '.apiServerArguments[\"audit-log-maxsize\"]'\nThe output should return a value of [\"100\"] or as appropriate.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"ocp-api-server-audit-log-maxsize"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-ocp-api-server-audit-log-maxsize","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692695","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-ocp-api-server-audit-log-maxsize","uid":"05ef0df0-347e-40c8-867e-ebc2f43b666b"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Configure the Audit Log Path\nAuditing of the API Server is not enabled by default. Auditing the API Server\nprovides a security-relevant chronological set of records documenting the sequence\nof activities that have affected the system by users, administrators, or other\nsystem components.","id":"xccdf_org.ssgproject.content_rule_openshift_api_server_audit_log_path","instructions":"Run the following command:\n$ oc get configmap config -n openshift-apiserver -ojson | jq -r '.data[\"config.yaml\"]' | jq '.apiServerArguments[\"audit-log-path\"]'\nThe output should return a valid audit log path.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"openshift-api-server-audit-log-path"},"creationTimestamp":"2021-06-03T17:09:18Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"high","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:18Z"}],"name":"ocp4-cis-openshift-api-server-audit-log-path","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692678","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-openshift-api-server-audit-log-path","uid":"5b3c27ee-8d35-48a6-ad3a-2a151e6b35b5"},"severity":"high","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Profiling is protected by RBAC\nProfiling allows for the identification of specific performance bottlenecks.\nIt generates a significant amount of program data that could potentially be\nexploited to uncover system and program details. If you are not experiencing\nany bottlenecks and do not need the profiler for troubleshooting purposes, it\nis recommended to turn it off to reduce the potential attack surface. To\nensure the collected data is not exploited, profiling endpoints are secured\nvia RBAC (see cluster-debugger role). By default, the profiling endpoints are\naccessible only by users bound to cluster-admin or cluster-debugger role.\nProfiling can not be disabled.","id":"xccdf_org.ssgproject.content_rule_rbac_debug_role_protects_pprof","instructions":"To verify that the cluster-debugger role is configured correctly,\nrun the following command:\n$ oc get clusterroles cluster-debugger -o jsonpath='{.rules[0].nonResourceURLs}'\nand verify that the /debug/pprof path is included there.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"rbac-debug-role-protects-pprof"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-rbac-debug-role-protects-pprof","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692697","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-rbac-debug-role-protects-pprof","uid":"6b5df37a-0466-4b00-bad2-b7c2d58cf558"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure that the cluster-admin role is only used where required\nKubernetes provides a set of default roles where RBAC is used. Some of these\nroles such as cluster-admin provide wide-ranging privileges which should\nonly be applied where absolutely necessary. Roles such as cluster-admin\nallow super-user access to perform any action on any resource. When used in\na ClusterRoleBinding, it gives full control over every resource in the\ncluster and in all namespaces. When used in a RoleBinding, it gives full\ncontrol over every resource in the rolebinding's namespace, including the\nnamespace itself.","id":"xccdf_org.ssgproject.content_rule_rbac_limit_cluster_admin","instructions":"Review users and groups bound to cluster-admin and decide whether they\nrequire such access. Consider creating least-privilege roles for users and\nservice accounts. Obtain a list of the users who have access to the\ncluster-admin role by reviewing the clusterrolebinding output for each role\nbinding that has access to the cluster-admin role. To do this, run the\nfollowing command:\n$ oc get clusterrolebindings -o=custom-columns=NAME:.metadata.name,ROLE:.roleRef.name,SUBJECT:.subjects[*].kind | grep cluster-admin\n\nCare should be taken before removing any clusterrolebindings from the\nenvironment to ensure they are not required for operation of the cluster.\nSpecifically, modifications should not be made to the default\nclusterrolebindings including those with the \"system:\" prefix.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"rbac-limit-cluster-admin"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-rbac-limit-cluster-admin","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692717","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-rbac-limit-cluster-admin","uid":"96586190-a6ef-4506-8655-6e35b9582c80"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Limit Access to Kubernetes Secrets\nInappropriate access to secrets stored within the Kubernetes\ncluster can allow for an attacker to gain additional access to\nthe Kubernetes cluster or external resources whose credentials\nare stored as secrets.","id":"xccdf_org.ssgproject.content_rule_rbac_limit_secrets_access","instructions":"To review the policy rules assigned to roles in all namespaces, run\nthe following command:\n$ for ns in $(oc get projects -ojsonpath='{.items[*].metadata.name}'); do oc describe roles -n$ns; done\nTo review the policy rules assigned to cluster roles, run the following\ncommand:\n$ for i in $(oc get clusterroles -o jsonpath='{.items[*].metadata.name}'); do oc describe clusterrole ${i}; done\nReview the output and ensure that only authorized roles have access to the\nsecrets resource or all resources using a wildcard.\nTo filter clusterroles that have assigned access to the secrets resources for clustrroles, run:\n$ oc get clusterroles -ojson | jq -r '.items[] | {name: .metadata.name, rules: .rules} | select(.rules[]?.resources | try contains([\"secrets\"])) | .name' | sort | uniq\nand similarly to filter namespace/role pairs:\n$ for ns in $(oc get projects -ojsonpath='{.items[*].metadata.name}'); do oc get roles -n$ns -ojson | jq -r '.items[] | {name: .metadata.name, namespace: .metadata.namespace, rules: .rules} | select(.rules[]?.resources | try contains([\"secrets\"])) | \"\\(.namespace)/\\(.name)\"' | sort | uniq; done\nnote that the two commands above do not show roles and/or clusterroles with wildcard access to any resources.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"rbac-limit-secrets-access"},"creationTimestamp":"2021-06-03T17:09:23Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:23Z"}],"name":"ocp4-cis-rbac-limit-secrets-access","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692817","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-rbac-limit-secrets-access","uid":"74e08bb7-aca4-4707-aef3-5542b1b5bbab"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Minimize Access to Pod Creation\nThe ability to create pods in a cluster opens up the cluster\nfor privilege escalation.","id":"xccdf_org.ssgproject.content_rule_rbac_pod_creation_access","instructions":"To review the pod creation privileges in roles, run the following commands:\n$ oc describe roles --all-namespaces\n$ oc describe clusterroles\nReview the output, and for any role/clusterrole defining create permissions\nfor pods that are NOT an OpenShift \"system:\" or other system-provided\nrole/clusterrole, determine if the users bound to the role truly have the\nneed to create pods.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"rbac-pod-creation-access"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-rbac-pod-creation-access","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692619","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-rbac-pod-creation-access","uid":"d791bf2e-0862-477d-81a0-afca0eea4a1e"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Minimize Wildcard Usage in Cluster and Local Roles\nThe principle of least privilege recommends that users are\nprovided only the access required for their role and nothing\nmore. The use of wildcard rights grants is likely to provide\nexcessive rights to the Kubernetes API.","id":"xccdf_org.ssgproject.content_rule_rbac_wildcard_use","instructions":"To review the wildcard usage in roles, run the following commands:\n$ oc describe roles --all-namespaces\n$ oc describe clusterroles\nReview the output, and for any role/clusterrole specifying a wildcard\nresource that is NOT an OpenShift \"system:\" or other system-provided\nrole/clusterrole, determine if the wildcard access can be replaced with\nspecific resources.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"rbac-wildcard-use"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-rbac-wildcard-use","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692784","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-rbac-wildcard-use","uid":"1d4f894e-87bf-4cf6-ba8b-50df2c9500c4"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Drop Container Capabilities\nBy default, containers run with a default set of capabilities as assigned\nby the Container Runtime which can include dangerous or highly privileged\ncapabilities. Capabilities should be dropped unless absolutely critical for\nthe container to run software as added capabilities that are not required\nallow for malicious containers or attackers.","id":"xccdf_org.ssgproject.content_rule_scc_drop_container_capabilities","instructions":"Inspect each SCC returned from running the following command:\n$ oc get scc\nNext, examine the outputs of the following commands:\n$ oc describe roles --all-namespaces\n$ oc describe clusterroles\nFor any role/clusterrole that reference the\nsecuritycontextconstraints resource with the resourceNames\nof the SCCs that do not list any requiredDropCapabilities, examine the\nassociated rolebindings to account for the users that are bound to the role.\nReview each SCC and determine that all capabilities are either\ncompletely disabled as a list entry under requiredDropCapabilities,\nor that all the un-required capabilities are dropped for containers and SCCs.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"scc-drop-container-capabilities"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-scc-drop-container-capabilities","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692621","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-scc-drop-container-capabilities","uid":"b647f976-062e-4696-8261-fdee7db383aa"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Limit Container Capabilities\nBy default, containers run with a default set of capabilities as assigned\nby the Container Runtime which can include dangerous or highly privileged\ncapabilities. Capabilities should be dropped unless absolutely critical for\nthe container to run software as added capabilities that are not required\nallow for malicious containers or attackers.","id":"xccdf_org.ssgproject.content_rule_scc_limit_container_allowed_capabilities","instructions":"Inspect each SCC returned from running the following command:\n$ oc get scc\nNext, examine the outputs of the following commands:\n$ oc describe roles --all-namespaces\n$ oc describe clusterroles\nFor any role/clusterrole that reference the\nsecuritycontextconstraints resource with the resourceNames\nof the SCCs that do not list an explicit allowedCapabilities, examine the\nassociated rolebindings to account for the users that are bound to the role.\nReview each SCC and determine that only required capabilities are either\ncompletely added as a list entry under allowedCapabilities,\nor that all the un-required capabilities are dropped for containers and SCCs.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"scc-limit-container-allowed-capabilities"},"creationTimestamp":"2021-06-03T17:09:22Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:22Z"}],"name":"ocp4-cis-scc-limit-container-allowed-capabilities","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692796","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-scc-limit-container-allowed-capabilities","uid":"63733e51-2fb9-44bd-ade0-3f9c00d82283"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Limit Access to the Host IPC Namespace\nA container running in the host's IPC namespace can use IPC\nto interact with processes outside the container potentially\nallowing an attacker to exploit a host process thereby enabling an\nattacker to exploit other services.","id":"xccdf_org.ssgproject.content_rule_scc_limit_ipc_namespace","instructions":"Inspect each SCC returned from running the following command:\n$ oc get scc\nReview each SCC for those that have allowHostIPC set to true.\nNext, examine the outputs of the following commands:\n$ oc describe roles --all-namespaces\n$ oc describe clusterroles\nFor any role/clusterrole that reference the\nsecuritycontextconstraints resource with the resourceNames\nof the SCCs that have allowHostIPC, examine the associated\nrolebindings to account for the users that are bound to the role. Review the\naccount to determine if allowHostIPC is truly required.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"scc-limit-ipc-namespace"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-scc-limit-ipc-namespace","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692742","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-scc-limit-ipc-namespace","uid":"7bcd18d7-d6ba-40fb-b19e-fcd0fdedbb72"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Limit Use of the CAP_NET_RAW\nBy default, containers run with a default set of capabilities as assigned\nby the Container Runtime which can include dangerous or highly privileged\ncapabilities. If the CAP_NET_RAW is enabled, it may be misused\nby malicious containers or attackers.","id":"xccdf_org.ssgproject.content_rule_scc_limit_net_raw_capability","instructions":"Inspect each SCC returned from running the following command:\n$ oc get scc\nReview each SCC for those that do not have NET_RAW or ALL set under requiredDropCapabilities.\nNext, examine the outputs of the following commands:\n$ oc describe roles --all-namespaces\n$ oc describe clusterroles\nFor any role/clusterrole that reference the\nsecuritycontextconstraints resource with the resourceNames\nof the SCCs that do not drop NET_RAW or ALL, examine the\nassociated rolebindings to account for the users that are bound to the role.\nReview each SCC and determine that either NET_RAW or ALL\nis either included as a list entry under requiredDropCapabilities,\nor that either NET_RAW or ALL is only enabled to a small\nset of containers and SCCs.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"scc-limit-net-raw-capability"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-scc-limit-net-raw-capability","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692738","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-scc-limit-net-raw-capability","uid":"d71576c7-9925-4300-b8cb-f4af914efbce"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Limit Access to the Host Network Namespace\nA container running in the host's network namespace could\naccess the host network traffic to and from other pods\npotentially allowing an attacker to exploit pods and network\ntraffic.","id":"xccdf_org.ssgproject.content_rule_scc_limit_network_namespace","instructions":"Inspect each SCC returned from running the following command:\n$ oc get scc\nReview each SCC for those that have allowHostNetwork set to true.\nNext, examine the outputs of the following commands:\n$ oc describe roles --all-namespaces\n$ oc describe clusterroles\nFor any role/clusterrole that reference the\nsecuritycontextconstraints resource with the resourceNames\nof the SCCs that have allowHostNetwork, examine the associated\nrolebindings to account for the users that are bound to the role. Review the\naccount to determine if allowHostNetwork is truly required.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"scc-limit-network-namespace"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-scc-limit-network-namespace","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692615","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-scc-limit-network-namespace","uid":"dee8f265-9c7b-4a71-8c17-027808b41069"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Limit Containers Ability to Escalate Privileges\nPrivileged containers have access to more of the Linux Kernel\ncapabilities and devices. If a privileged container were\ncompromised, an attacker would have full access to the container\nand host.","id":"xccdf_org.ssgproject.content_rule_scc_limit_privilege_escalation","instructions":"Inspect each SCC returned from running the following command:\n$ oc get scc\nReview each SCC for those that have allowPrivilegeEscalation set to true.\nNext, examine the outputs of the following commands:\n$ oc describe roles --all-namespaces\n$ oc describe clusterroles\nFor any role/clusterrole that reference the\nsecuritycontextconstraints resource with the resourceNames\nof the SCCs that have allowPrivilegeEscalation, examine the associated\nrolebindings to account for the users that are bound to the role. Review the\naccount to determine if allowPrivilegeEscalation is truly required.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"scc-limit-privilege-escalation"},"creationTimestamp":"2021-06-03T17:09:24Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:24Z"}],"name":"ocp4-cis-scc-limit-privilege-escalation","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692869","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-scc-limit-privilege-escalation","uid":"73432c52-4e29-4c98-89c1-271cc6f58620"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Limit Privileged Container Use\nPrivileged containers have access to all Linux Kernel\ncapabilities and devices. If a privileged container were\ncompromised, an attacker would have full access to the container\nand host.","id":"xccdf_org.ssgproject.content_rule_scc_limit_privileged_containers","instructions":"Inspect each SCC returned from running the following command:\n$ oc get scc\nReview each SCC for those that have allowPrivilegedContainer set to true.\nNext, examine the outputs of the following commands:\n$ oc describe roles --all-namespaces\n$ oc describe clusterroles\nFor any role/clusterrole that reference the\nsecuritycontextconstraints resource with the resourceNames\nof the SCCs that have allowPrivilegedContainer, examine the associated\nrolebindings to account for the users that are bound to the role. Review the\naccount to determine if allowPrivilegedContainer is truly required.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"scc-limit-privileged-containers"},"creationTimestamp":"2021-06-03T17:09:19Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:19Z"}],"name":"ocp4-cis-scc-limit-privileged-containers","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692699","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-scc-limit-privileged-containers","uid":"6d2f060d-a1ba-42b8-9888-e96cee748920"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Limit Access to the Host Process ID Namespace\nA container running in the host's PID namespace can inspect\nprocesses running outside the container which can be used to\nescalate privileges outside of the container.","id":"xccdf_org.ssgproject.content_rule_scc_limit_process_id_namespace","instructions":"Inspect each SCC returned from running the following command:\n$ oc get scc\nReview each SCC for those that have allowHostPID set to true.\nNext, examine the outputs of the following commands:\n$ oc describe roles --all-namespaces\n$ oc describe clusterroles\nFor any role/clusterrole that reference the\nsecuritycontextconstraints resource with the resourceNames\nof the SCCs that have allowHostPID, examine the associated\nrolebindings to account for the users that are bound to the role. Review the\naccount to determine if allowHostPID is truly required.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"scc-limit-process-id-namespace"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-scc-limit-process-id-namespace","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692620","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-scc-limit-process-id-namespace","uid":"02067fb4-59aa-455c-94d6-3b2ff76a0983"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Limit Container Running As Root User\nPrivileged containers have access to all Linux Kernel\ncapabilities and devices. If a privileged container were\ncompromised, an attacker would have full access to the container\nand host.","id":"xccdf_org.ssgproject.content_rule_scc_limit_root_containers","instructions":"Inspect each SCC returned from running the following command:\n$ oc get scc\nReview each SCC for those that have allowPrivilegedContainer set to true.\nNext, examine the outputs of the following commands:\n$ oc describe roles --all-namespaces\n$ oc describe clusterroles\nFor any role/clusterrole that reference the\nsecuritycontextconstraints resource with the resourceNames\nof the SCCs that have allowPrivilegedContainer, examine the associated\nrolebindings to account for the users that are bound to the role. Review the\naccount to determine if allowPrivilegedContainer is truly required.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"scc-limit-root-containers"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-scc-limit-root-containers","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692614","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-scc-limit-root-containers","uid":"8ec59bc8-b2d2-4c97-880d-a25e8c638c96"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Ensure that the bind-address parameter is not used\nIn OpenShift 4, The Kubernetes Scheduler operator manages and updates the\nKubernetes Scheduler deployed on top of OpenShift. By default, the operator\nexposes metrics via metrics service. The metrics are collected from the\nKubernetes Scheduler operator. Profiling data is sent to healthzPort,\nthe port of the localhost healthz endpoint. Changing this value may disrupt\ncomponents that monitor the kubelet health.","id":"xccdf_org.ssgproject.content_rule_scheduler_no_bind_address","instructions":"Run the following command:\noc get -nopenshift-kube-scheduler cm kube-scheduler-pod -ojson | jq -r '.data[\"pod.yaml\"]' | jq -r | grep bind-address\nThe output should be empty","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"scheduler-no-bind-address"},"creationTimestamp":"2021-06-03T17:09:16Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"PASS","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:16Z"}],"name":"ocp4-cis-scheduler-no-bind-address","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692616","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-scheduler-no-bind-address","uid":"e5fe0976-7ab6-4ad8-92d2-9a5b8ccac2ed"},"severity":"medium","status":"PASS"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Consider external secret storage\nKubernetes supports secrets as first-class objects, but care needs to be\ntaken to ensure that access to secrets is carefully limited. Using an\nexternal secrets provider can ease the management of access to secrets,\nespecially where secrets are used across both Kubernetes and non-Kubernetes\nenvironments.","id":"xccdf_org.ssgproject.content_rule_secrets_consider_external_storage","instructions":"Review the cluster configuration and determine if an appropriate secrets\nmanager has been configured.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"secrets-consider-external-storage"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-secrets-consider-external-storage","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692719","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-secrets-consider-external-storage","uid":"44c45fcc-cd73-4d43-b4a0-a36d0c23cd7c"},"severity":"medium","status":"MANUAL"},{"apiVersion":"compliance.openshift.io/v1alpha1","description":"Do Not Use Environment Variables with Secrets\nEnvironment variables are subject and very susceptible to\nmalicious hijacking methods by an adversary, as such,\nenvironment variables should never be used for secrets.","id":"xccdf_org.ssgproject.content_rule_secrets_no_environment_variables","instructions":"To find workloads that use environment variables for secrets, run the following:\n$ oc get all -o jsonpath='{range .items[?(@..secretKeyRef)]} {.kind} {.metadata.namespace} {.metadata.name} {\"\\n\"}{end}' -A\nReview the output and ensure that workloads that can mount secrets as data\nvolumes use that instead of environment variables.","kind":"ComplianceCheckResult","metadata":{"annotations":{"compliance.openshift.io/rule":"secrets-no-environment-variables"},"creationTimestamp":"2021-06-03T17:09:20Z","generation":1,"labels":{"compliance.openshift.io/check-severity":"medium","compliance.openshift.io/check-status":"MANUAL","compliance.openshift.io/scan-name":"ocp4-cis","compliance.openshift.io/suite":"cis-compliance"},"managedFields":[{"apiVersion":"compliance.openshift.io/v1alpha1","fieldsType":"FieldsV1","fieldsV1":{"f:description":{},"f:id":{},"f:instructions":{},"f:metadata":{"f:annotations":{".":{},"f:compliance.openshift.io/rule":{}},"f:labels":{".":{},"f:compliance.openshift.io/check-severity":{},"f:compliance.openshift.io/check-status":{},"f:compliance.openshift.io/scan-name":{},"f:compliance.openshift.io/suite":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"66066c3c-8815-423e-8c21-8ccf13e1b11e\"}":{".":{},"f:apiVersion":{},"f:blockOwnerDeletion":{},"f:controller":{},"f:kind":{},"f:name":{},"f:uid":{}}}},"f:severity":{},"f:status":{}},"manager":"compliance-operator","operation":"Update","time":"2021-06-03T17:09:20Z"}],"name":"ocp4-cis-secrets-no-environment-variables","namespace":"openshift-compliance","ownerReferences":[{"apiVersion":"compliance.openshift.io/v1alpha1","blockOwnerDeletion":true,"controller":true,"kind":"ComplianceScan","name":"ocp4-cis","uid":"66066c3c-8815-423e-8c21-8ccf13e1b11e"}],"resourceVersion":"44692744","selfLink":"/apis/compliance.openshift.io/v1alpha1/namespaces/openshift-compliance/compliancecheckresults/ocp4-cis-secrets-no-environment-variables","uid":"31006c8b-c0b8-4d55-8f2e-6fb8fa01a3fa"},"severity":"medium","status":"MANUAL"}]}